{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.15.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from IMPORTS import *\n",
    "import pandas as pd\n",
    "seed_value = 18\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = fasttext.load_model('WordEmbeddings/cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading ATE json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATE_train = None\n",
    "ATE_test = None\n",
    "ATE_val = None\n",
    "with open(\"Task1\\processed\\ATE_train.json\") as f1:\n",
    "    ATE_train  = json.load(f1)\n",
    "\n",
    "with open(\"Task1\\processed\\ATE_test.json\") as f2:\n",
    "    ATE_test = json.load(f2)\n",
    "\n",
    "with open(\"Task1\\processed\\ATE_val.json\") as f3:\n",
    "    ATE_val = json.load(f3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATE Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ate,Y_train_ate= create_train_test_val(ATE_train)\n",
    "X_test_ate,Y_test_ate = create_train_test_val(ATE_test)\n",
    "X_val_ate,Y_val_ate = create_train_test_val(ATE_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing the ATE Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ate_tokenized, toke = TokenCreator(X_train_ate,1)\n",
    "X_test_ate_tokenized = TokenCreator(X_test_ate,0,tokenizer = toke)\n",
    "X_val_ate_tokenized = TokenCreator(X_val_ate,0,tokenizer = toke)\n",
    "\n",
    "Y_train_ate_tokenized,toke2 = TokenCreator(Y_train_ate,0)\n",
    "Y_test_ate_tokenized = TokenCreator(Y_test_ate,0,tokenizer = toke2)\n",
    "Y_val_ate_tokenized = TokenCreator(Y_val_ate,0,tokenizer = toke2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabulary of ATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2406"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "st1 = find_vocab(X_train_ate_tokenized)\n",
    "vocab_size_ate  = len(st1) + 1 \n",
    "vocab_size_ate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding ATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_padded_train = pad_sequences(X_train_ate_tokenized, maxlen=100, padding=\"pre\", truncating=\"post\")\n",
    "Y_padded_train = pad_sequences(Y_train_ate_tokenized, maxlen=100, padding=\"pre\", truncating=\"post\")\n",
    "\n",
    "X_padded_test = pad_sequences(X_test_ate_tokenized, maxlen=100, padding=\"pre\", truncating=\"post\")\n",
    "Y_padded_test = pad_sequences(Y_test_ate_tokenized, maxlen=100, padding=\"pre\", truncating=\"post\")\n",
    "\n",
    "X_padded_val = pad_sequences(X_val_ate_tokenized, maxlen=100, padding=\"pre\", truncating=\"post\")\n",
    "Y_padded_val = pad_sequences(Y_val_ate_tokenized, maxlen=100, padding=\"pre\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding the ATE labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_padded_train = to_categorical(Y_padded_train)\n",
    "Y_padded_test = to_categorical(Y_padded_test)\n",
    "Y_padded_val = to_categorical(Y_padded_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning **ATE Fasttext** mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_ate_ft = np.zeros((vocab_size_ate, 300))\n",
    "\n",
    "mapping_ate_ft = toke.word_index \n",
    "mapping_ate_ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching weights from pre trained Fasttext model (ATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, index in mapping_ate_ft.items():\n",
    "    if word in ft:\n",
    "        weights_ate_ft[index:] = ft[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the rnn Model using Fasttext embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model_ft = Sequential()\n",
    "rnn_model_ft.add(Embedding(input_dim = vocab_size_ate,output_dim = 300,input_length  = 100,weights = [weights_ate_ft],trainable = False))\n",
    "rnn_model_ft.add(SimpleRNN(64, return_sequences=True))\n",
    "rnn_model_ft.add(TimeDistributed(Dense(Y_padded_train.shape[2], activation='softmax')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling the rnn Fasttext Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model_ft.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc',Precision(),Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_f1_callback_val = F1ScoreCallback(data=(X_padded_val, Y_padded_val),name='validation')\n",
    "rnn_f1_callback_train=F1ScoreCallback(data=(X_padded_train, Y_padded_train),name='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model_ft.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the rnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_training_ft = rnn_model_ft.fit(X_padded_train, Y_padded_train, batch_size=128, epochs=15, validation_data=(X_padded_val, Y_padded_val), callbacks=[rnn_f1_callback_train,rnn_f1_callback_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = rnn_model_ft.evaluate(X_padded_test, Y_padded_test, verbose = 1)\n",
    "print(accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_ate = rnn_model_ft.predict(X_padded_test)\n",
    "real = get_real(Y_padded_test)\n",
    "pred = get_pred(Y_pred_ate)\n",
    "f1 = F1Score(average='macro')\n",
    "f1.update_state(real,pred)\n",
    "f1_score = f1.result().numpy()\n",
    "print(f\"F1 Score ATE : {f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_loss_graph(rnn_training_ft, \"rnn Model\", rnn_f1_callback_train.f1_scores, rnn_f1_callback_val.f1_scores)\n",
    "save_model(rnn_model_ft, \"rnn\",\"FastText\",\"t2\")\n",
    "loaded_model = load_model(\"Saved_Models/ATE/t2_rnn_FastText.pkl\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
