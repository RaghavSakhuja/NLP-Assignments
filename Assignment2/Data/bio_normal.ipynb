{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_escape_sequences(input_string):\n",
    "    # Using regular expression to replace multiple spaces with a single space\n",
    "    # input_string= re.sub(r'\\s+', ' ', input_string)\n",
    "    return re.sub(r'[\\n\\r\\t\\f\\v]', ' ', input_string)\n",
    "\n",
    "def bio_tagging_2(words,aspects):\n",
    "    labels=['O' for i in range(len(words))]\n",
    "    for i in aspects:\n",
    "        s=i['term']\n",
    "        start=i['from']\n",
    "        end=i['to'] \n",
    "        labels[start]=\"B\"\n",
    "        for j in range(start+1,end):\n",
    "            labels[j]=\"I\"\n",
    "    return labels\n",
    "\n",
    "def bio_tagging_1(values,text):\n",
    "    text=convert_escape_sequences(text)\n",
    "    words=text.split(\" \")\n",
    "    labels=['O' for i in range(len(words))]\n",
    "    curr=0\n",
    "    currcount=0\n",
    "\n",
    "    for i in values:\n",
    "        i=i['value']\n",
    "        start=i['start']\n",
    "        end=i['end']\n",
    "        s=text[start:end+1].split()\n",
    "        label=i['labels'][0]\n",
    "        while(curr<len(words)):\n",
    "            # if ' '.join(s) in ' '.join(words[curr:curr+len(s)]):\n",
    "            if currcount+len(words[curr])>=start:\n",
    "                labels[curr]=\"B_\"+label\n",
    "                currcount+=len(words[curr])+1\n",
    "                curr+=1\n",
    "                \n",
    "                while(currcount<end):\n",
    "                # for j in range(len(s)-1):\n",
    "                    labels[curr]='I_'+label\n",
    "                    currcount+=len(words[curr])+1\n",
    "                    curr+=1\n",
    "                break\n",
    "            currcount+=len(words[curr])+1\n",
    "            curr+=1\n",
    "    i=0\n",
    "    while(i<len(words)):\n",
    "        if words[i]==\"\":\n",
    "            words.pop(i)\n",
    "            labels.pop(i)\n",
    "        i+=1\n",
    "    # print(words)\n",
    "    return (\" \".join(words),labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER_JUDGEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_1(input,file):\n",
    "    data={}\n",
    "    for i in input:\n",
    "        values=i['annotations'][0]['result']\n",
    "        text=i['data']['text']\n",
    "        words,labels=bio_tagging_1(values,text)\n",
    "        data[i['id']]={\"text\":words,\"labels\":labels}\n",
    "    file_path = \"processed/\"+file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(data, json_file,indent=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file=\"NER_TRAIN_JUDGEMENT.json\"\n",
    "f = open(input_file,)\n",
    "input=json.load(f)\n",
    "\n",
    "input_data=[[],[]]\n",
    "for i in input:\n",
    "    values=i['annotations'][0]['result']\n",
    "    text=i['data']['text']\n",
    "    input_data[0].append(values)\n",
    "    input_data[1].append(text)\n",
    "train,val=train_test_split(input,test_size=0.15,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_1(train,\"NER_train.json\")\n",
    "file_1(val,\"NER_val.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "949\n"
     ]
    }
   ],
   "source": [
    "input_file=\"NER_TEST_JUDGEMENT.json\"\n",
    "f = open(input_file,)\n",
    "test=json.load(f)\n",
    "print(len(test))\n",
    "file_1(test,\"NER_test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laptop Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=json.load(open(\"Laptop_Review_Train.json\"))\n",
    "val=json.load(open(\"Laptop_Review_Val.json\"))\n",
    "test=json.load(open(\"Laptop_Review_Test.json\"))\n",
    "def func(input,output_name):\n",
    "    data={}\n",
    "    count=0\n",
    "    for i in input:\n",
    "        words=i['words']\n",
    "        aspects=i['aspects']\n",
    "        text=i['raw_words']\n",
    "        # print(bio_tagging_2(words,aspects))\n",
    "        data[count]={\"text\":text,\"labels\":bio_tagging_2(words,aspects)}\n",
    "        count+=1\n",
    "        # break\n",
    "    file_path = \"processed/\"+output_name+\".json\"\n",
    "    # # Write data to JSON file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(data, json_file,indent=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "func(train,\"ATE_train\")\n",
    "func(val,\"ATE_val\")\n",
    "func(test,\"ATE_test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
