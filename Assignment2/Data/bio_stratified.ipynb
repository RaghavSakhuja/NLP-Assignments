{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from skmultilearn.model_selection import IterativeStratification\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_escape_sequences(input_string):\n",
    "    # Using regular expression to replace multiple spaces with a single space\n",
    "    # input_string= re.sub(r'\\s+', ' ', input_string)\n",
    "    return re.sub(r'[\\n\\r\\t\\f\\v]', ' ', input_string)\n",
    "\n",
    "def bio_tagging_2(words,aspects):\n",
    "    labels=['O' for i in range(len(words))]\n",
    "    for i in aspects:\n",
    "        s=i['term']\n",
    "        start=i['from']\n",
    "        end=i['to'] \n",
    "        labels[start]=\"B\"\n",
    "        for j in range(start+1,end):\n",
    "            labels[j]=\"I\"\n",
    "    return labels\n",
    "\n",
    "def bio_tagging_1(values,text):\n",
    "    text=convert_escape_sequences(text)\n",
    "    words=text.split(\" \")\n",
    "    labels=['O' for i in range(len(words))]\n",
    "    curr=0\n",
    "    currcount=0\n",
    "\n",
    "    for i in values:\n",
    "        i=i['value']\n",
    "        start=i['start']\n",
    "        end=i['end']\n",
    "        s=text[start:end+1].split()\n",
    "        label=i['labels'][0]\n",
    "        while(curr<len(words)):\n",
    "            # if ' '.join(s) in ' '.join(words[curr:curr+len(s)]):\n",
    "            if currcount+len(words[curr])>=start:\n",
    "                labels[curr]=\"B_\"+label\n",
    "                currcount+=len(words[curr])+1\n",
    "                curr+=1\n",
    "                \n",
    "                while(currcount<end):\n",
    "                # for j in range(len(s)-1):\n",
    "                    labels[curr]='I_'+label\n",
    "                    currcount+=len(words[curr])+1\n",
    "                    curr+=1\n",
    "                break\n",
    "            currcount+=len(words[curr])+1\n",
    "            curr+=1\n",
    "    i=0\n",
    "    while(i<len(words)):\n",
    "        if words[i]==\"\":\n",
    "            words.pop(i)\n",
    "            labels.pop(i)\n",
    "        i+=1\n",
    "    # print(words)\n",
    "    return (\" \".join(words),labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER_JUDGEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_1(input,file):\n",
    "    data={}\n",
    "    # print(input[0])\n",
    "    for i in input:\n",
    "        id=i[0]\n",
    "        values=i[1]\n",
    "        text=i[2]\n",
    "        words,labels=bio_tagging_1(values,text)\n",
    "        data[id]={\"text\":words,\"labels\":labels}\n",
    "    file_path = \"stratified/\"+file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(data, json_file,indent=3)\n",
    "def file_1_2(input,file):\n",
    "    data={}\n",
    "    for i in input:\n",
    "        values=i['annotations'][0]['result']\n",
    "        text=i['data']['text']\n",
    "        words,labels=bio_tagging_1(values,text)\n",
    "        data[i['id']]={\"text\":words,\"labels\":labels}\n",
    "    file_path = \"stratified/\"+file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(data, json_file,indent=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PROVISION': 0, 'ORG': 1, 'GPE': 2, 'CASE_NUMBER': 3, 'WITNESS': 4, 'RESPONDENT': 5, 'OTHER_PERSON': 6, 'STATUTE': 7, 'DATE': 8, 'COURT': 9, 'PETITIONER': 10, 'JUDGE': 11, 'PRECEDENT': 12}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_file=\"NER_TRAIN_JUDGEMENT.json\"\n",
    "f = open(input_file,)\n",
    "input=json.load(f)\n",
    "input_data=[[],[],[]]\n",
    "labelset=set()\n",
    "labeldict={}\n",
    "for i in input:\n",
    "    id=i['id']\n",
    "    values=i['annotations'][0]['result']\n",
    "    text=i['data']['text']\n",
    "    input_data[0].append(id)\n",
    "    input_data[1].append(values)\n",
    "    input_data[2].append(text)\n",
    "    # print(input_data[0][-1])\n",
    "    for i in input_data[1][-1]:\n",
    "        labelset.add(i['value']['labels'][0])\n",
    "        # if i['labels'][0] not in labeldict:\n",
    "        #     labeldict[i['labels'][0]]=len(labeldict)\n",
    "for i in labelset:\n",
    "    labeldict[i]=len(labeldict)\n",
    "print(labeldict)\n",
    "label_matrix=[]\n",
    "for i in range(len(input_data[1])):\n",
    "    label_matrix.append([0 for j in range(len(labeldict))])\n",
    "for i in range(len(input_data[1])):\n",
    "    for j in input_data[1][i]:\n",
    "        label_matrix[i][labeldict[j['value']['labels'][0]]]=1\n",
    "\n",
    "\n",
    "\n",
    "input_data=np.column_stack(input_data)\n",
    "input_data,label_matrix=shuffle(input_data,label_matrix,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9435, 3)\n",
      "(9435, 13)\n"
     ]
    }
   ],
   "source": [
    "input=input_data\n",
    "label_matrix=np.array(label_matrix)\n",
    "\n",
    "print(input.shape)\n",
    "print(label_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "is1=IterativeStratification(n_splits=2, order=1, sample_distribution_per_fold=[0.85, 0.15])\n",
    "for train_index, test_index in is1.split(input, label_matrix):\n",
    "    X_train, X_test = input[train_index], input[test_index]\n",
    "    y_train, y_test = label_matrix[train_index], label_matrix[test_index]\n",
    "\n",
    "train=[X_train,y_train]\n",
    "val=[X_test,y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(X_train[0][0])\n",
    "file_1(X_train,\"NER_train.json\")\n",
    "file_1(X_test,\"NER_val.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "949\n"
     ]
    }
   ],
   "source": [
    "input_file=\"NER_TEST_JUDGEMENT.json\"\n",
    "f = open(input_file,)\n",
    "test=json.load(f)\n",
    "print(len(test))\n",
    "file_1_2(test,\"NER_test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laptop Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=json.load(open(\"Laptop_Review_Train.json\"))\n",
    "val=json.load(open(\"Laptop_Review_Val.json\"))\n",
    "test=json.load(open(\"Laptop_Review_Test.json\"))\n",
    "def func(input,output_name):\n",
    "    data={}\n",
    "    count=0\n",
    "    for i in input:\n",
    "        words=i['words']\n",
    "        aspects=i['aspects']\n",
    "        text=i['raw_words']\n",
    "        # print(bio_tagging_2(words,aspects))\n",
    "        data[count]={\"text\":text,\"labels\":bio_tagging_2(words,aspects)}\n",
    "        count+=1\n",
    "        # break\n",
    "    file_path = \"stratified/\"+output_name+\".json\"\n",
    "    # # Write data to JSON file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(data, json_file,indent=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "func(train,\"ATE_train\")\n",
    "func(val,\"ATE_val\")\n",
    "func(test,\"ATE_test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
