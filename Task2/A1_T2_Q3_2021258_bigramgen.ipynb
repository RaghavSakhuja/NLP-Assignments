{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7546040,"sourceType":"datasetVersion","datasetId":4390111},{"sourceId":7546139,"sourceType":"datasetVersion","datasetId":4394705}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"div=1# 1,3,5,7\ncorpus=[]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-03T14:18:30.177149Z","iopub.execute_input":"2024-02-03T14:18:30.177504Z","iopub.status.idle":"2024-02-03T14:18:30.181702Z","shell.execute_reply.started":"2024-02-03T14:18:30.177478Z","shell.execute_reply":"2024-02-03T14:18:30.180833Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import time\nimport pandas as pd\nfrom transformers import pipeline\nfrom itertools import combinations\nfrom transformers.utils import logging\n\nlogging.set_verbosity_info()\nlogger = logging.get_logger(\"transformers\")\nlogger.info(\"INFO\")\nclassifier = pipeline(\"text-classification\", model='bhadresh-savani/distilbert-base-uncased-emotion',batch_size=550, return_all_scores=True,device=0)\n\ndef emotion_scores(words):\n    # print(words)\n    emotions = classifier(words)\n    # print(emotions[0])\n    return [[e['score'] for e in emotions[i]] for i in range(len(emotions))]\n\ndef generate_bigrams(corpus):\n    df=pd.read_csv(\"/kaggle/input/corpus/bigrams_left.csv\")\n    df=df[\"bigram_left\"]\n#     df=df[0:100]\n    size=len(df)\n    \n    return list(df[((div-1)*(size//8)):((div)*(size//8))])\n\nstart_time = time.time()\n\n# Generate bigrams from the corpus\nbigrams = generate_bigrams(corpus)\n\n# Accumulate bigram data in a list\nbigram_input = bigrams\n# for bigram in bigrams:\n# #   # Combine bigram words into a single string\n#     bigram_text = \" \".join(bigram)\n#     # Append bigram data to the list\n#     bigram_input.append(bigram_text)\n\n#calculate emotions for all bigrams\nemotions = emotion_scores(bigram_input)\n\n# Process the bigram\nbigram_data=[]\nfor i in range(len(bigram_input)):\n    bigram_data.append([bigram_input[i]]+emotions[i])\n\n\n# Create a DataFrame for all bigrams\n","metadata":{"execution":{"iopub.status.busy":"2024-02-03T14:18:30.183323Z","iopub.execute_input":"2024-02-03T14:18:30.183601Z","iopub.status.idle":"2024-02-03T14:34:46.732251Z","shell.execute_reply.started":"2024-02-03T14:18:30.183578Z","shell.execute_reply":"2024-02-03T14:34:46.731401Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"INFO\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bhadresh-savani--distilbert-base-uncased-emotion/snapshots/5c2417f094aed91e6c1b0748888adb5839839eee/config.json\nModel config DistilBertConfig {\n  \"_name_or_path\": \"bhadresh-savani/distilbert-base-uncased-emotion\",\n  \"activation\": \"gelu\",\n  \"architectures\": [\n    \"DistilBertForSequenceClassification\"\n  ],\n  \"attention_dropout\": 0.1,\n  \"dim\": 768,\n  \"dropout\": 0.1,\n  \"hidden_dim\": 3072,\n  \"id2label\": {\n    \"0\": \"sadness\",\n    \"1\": \"joy\",\n    \"2\": \"love\",\n    \"3\": \"anger\",\n    \"4\": \"fear\",\n    \"5\": \"surprise\"\n  },\n  \"initializer_range\": 0.02,\n  \"label2id\": {\n    \"anger\": 3,\n    \"fear\": 4,\n    \"joy\": 1,\n    \"love\": 2,\n    \"sadness\": 0,\n    \"surprise\": 5\n  },\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"distilbert\",\n  \"n_heads\": 12,\n  \"n_layers\": 6,\n  \"pad_token_id\": 0,\n  \"qa_dropout\": 0.1,\n  \"seq_classif_dropout\": 0.2,\n  \"sinusoidal_pos_embds\": false,\n  \"tie_weights_\": true,\n  \"transformers_version\": \"4.37.0\",\n  \"vocab_size\": 30522\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bhadresh-savani--distilbert-base-uncased-emotion/snapshots/5c2417f094aed91e6c1b0748888adb5839839eee/config.json\nModel config DistilBertConfig {\n  \"_name_or_path\": \"bhadresh-savani/distilbert-base-uncased-emotion\",\n  \"activation\": \"gelu\",\n  \"architectures\": [\n    \"DistilBertForSequenceClassification\"\n  ],\n  \"attention_dropout\": 0.1,\n  \"dim\": 768,\n  \"dropout\": 0.1,\n  \"hidden_dim\": 3072,\n  \"id2label\": {\n    \"0\": \"sadness\",\n    \"1\": \"joy\",\n    \"2\": \"love\",\n    \"3\": \"anger\",\n    \"4\": \"fear\",\n    \"5\": \"surprise\"\n  },\n  \"initializer_range\": 0.02,\n  \"label2id\": {\n    \"anger\": 3,\n    \"fear\": 4,\n    \"joy\": 1,\n    \"love\": 2,\n    \"sadness\": 0,\n    \"surprise\": 5\n  },\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"distilbert\",\n  \"n_heads\": 12,\n  \"n_layers\": 6,\n  \"pad_token_id\": 0,\n  \"qa_dropout\": 0.1,\n  \"seq_classif_dropout\": 0.2,\n  \"sinusoidal_pos_embds\": false,\n  \"tie_weights_\": true,\n  \"transformers_version\": \"4.37.0\",\n  \"vocab_size\": 30522\n}\n\nloading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bhadresh-savani--distilbert-base-uncased-emotion/snapshots/5c2417f094aed91e6c1b0748888adb5839839eee/pytorch_model.bin\nAll model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n\nAll the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at bhadresh-savani/distilbert-base-uncased-emotion.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bhadresh-savani--distilbert-base-uncased-emotion/snapshots/5c2417f094aed91e6c1b0748888adb5839839eee/config.json\nModel config DistilBertConfig {\n  \"_name_or_path\": \"bhadresh-savani/distilbert-base-uncased-emotion\",\n  \"activation\": \"gelu\",\n  \"architectures\": [\n    \"DistilBertForSequenceClassification\"\n  ],\n  \"attention_dropout\": 0.1,\n  \"dim\": 768,\n  \"dropout\": 0.1,\n  \"hidden_dim\": 3072,\n  \"id2label\": {\n    \"0\": \"sadness\",\n    \"1\": \"joy\",\n    \"2\": \"love\",\n    \"3\": \"anger\",\n    \"4\": \"fear\",\n    \"5\": \"surprise\"\n  },\n  \"initializer_range\": 0.02,\n  \"label2id\": {\n    \"anger\": 3,\n    \"fear\": 4,\n    \"joy\": 1,\n    \"love\": 2,\n    \"sadness\": 0,\n    \"surprise\": 5\n  },\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"distilbert\",\n  \"n_heads\": 12,\n  \"n_layers\": 6,\n  \"pad_token_id\": 0,\n  \"qa_dropout\": 0.1,\n  \"seq_classif_dropout\": 0.2,\n  \"sinusoidal_pos_embds\": false,\n  \"tie_weights_\": true,\n  \"transformers_version\": \"4.37.0\",\n  \"vocab_size\": 30522\n}\n\nloading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bhadresh-savani--distilbert-base-uncased-emotion/snapshots/5c2417f094aed91e6c1b0748888adb5839839eee/vocab.txt\nloading file tokenizer.json from cache at None\nloading file added_tokens.json from cache at None\nloading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--bhadresh-savani--distilbert-base-uncased-emotion/snapshots/5c2417f094aed91e6c1b0748888adb5839839eee/special_tokens_map.json\nloading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bhadresh-savani--distilbert-base-uncased-emotion/snapshots/5c2417f094aed91e6c1b0748888adb5839839eee/tokenizer_config.json\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bhadresh-savani--distilbert-base-uncased-emotion/snapshots/5c2417f094aed91e6c1b0748888adb5839839eee/config.json\nModel config DistilBertConfig {\n  \"_name_or_path\": \"bhadresh-savani/distilbert-base-uncased-emotion\",\n  \"activation\": \"gelu\",\n  \"architectures\": [\n    \"DistilBertForSequenceClassification\"\n  ],\n  \"attention_dropout\": 0.1,\n  \"dim\": 768,\n  \"dropout\": 0.1,\n  \"hidden_dim\": 3072,\n  \"id2label\": {\n    \"0\": \"sadness\",\n    \"1\": \"joy\",\n    \"2\": \"love\",\n    \"3\": \"anger\",\n    \"4\": \"fear\",\n    \"5\": \"surprise\"\n  },\n  \"initializer_range\": 0.02,\n  \"label2id\": {\n    \"anger\": 3,\n    \"fear\": 4,\n    \"joy\": 1,\n    \"love\": 2,\n    \"sadness\": 0,\n    \"surprise\": 5\n  },\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"distilbert\",\n  \"n_heads\": 12,\n  \"n_layers\": 6,\n  \"pad_token_id\": 0,\n  \"qa_dropout\": 0.1,\n  \"seq_classif_dropout\": 0.2,\n  \"sinusoidal_pos_embds\": false,\n  \"tie_weights_\": true,\n  \"transformers_version\": \"4.37.0\",\n  \"vocab_size\": 30522\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bhadresh-savani--distilbert-base-uncased-emotion/snapshots/5c2417f094aed91e6c1b0748888adb5839839eee/config.json\nModel config DistilBertConfig {\n  \"_name_or_path\": \"bhadresh-savani/distilbert-base-uncased-emotion\",\n  \"activation\": \"gelu\",\n  \"architectures\": [\n    \"DistilBertForSequenceClassification\"\n  ],\n  \"attention_dropout\": 0.1,\n  \"dim\": 768,\n  \"dropout\": 0.1,\n  \"hidden_dim\": 3072,\n  \"id2label\": {\n    \"0\": \"sadness\",\n    \"1\": \"joy\",\n    \"2\": \"love\",\n    \"3\": \"anger\",\n    \"4\": \"fear\",\n    \"5\": \"surprise\"\n  },\n  \"initializer_range\": 0.02,\n  \"label2id\": {\n    \"anger\": 3,\n    \"fear\": 4,\n    \"joy\": 1,\n    \"love\": 2,\n    \"sadness\": 0,\n    \"surprise\": 5\n  },\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"distilbert\",\n  \"n_heads\": 12,\n  \"n_layers\": 6,\n  \"pad_token_id\": 0,\n  \"qa_dropout\": 0.1,\n  \"seq_classif_dropout\": 0.2,\n  \"sinusoidal_pos_embds\": false,\n  \"tie_weights_\": true,\n  \"transformers_version\": \"4.37.0\",\n  \"vocab_size\": 30522\n}\n\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:105: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nDisabling tokenizer parallelism, we're using DataLoader multithreading already\n","output_type":"stream"}]},{"cell_type":"code","source":"columns = [\"bigram\", \"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\ndf = pd.DataFrame(bigram_data, columns=columns)\n\n# Save the DataFrame to a CSV file\ndf.to_csv(f\"emotion_scores_bigrams_{div}.csv\", index=False)\n\nend_time = time.time()\nelapsed_time = end_time - start_time\n\n# # Print the result\nprint(f\"Elapsed time: {elapsed_time} seconds\")","metadata":{"execution":{"iopub.status.busy":"2024-02-03T14:34:46.733869Z","iopub.execute_input":"2024-02-03T14:34:46.734251Z","iopub.status.idle":"2024-02-03T14:35:24.226495Z","shell.execute_reply.started":"2024-02-03T14:34:46.734222Z","shell.execute_reply":"2024-02-03T14:35:24.225564Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Elapsed time: 1013.7097387313843 seconds\n","output_type":"stream"}]},{"cell_type":"code","source":"import time\nimport pandas as pd\nfrom transformers import pipeline\nfrom itertools import combinations\nfrom transformers.utils import logging\n\nlogging.set_verbosity_info()\nlogger = logging.get_logger(\"transformers\")\nlogger.info(\"INFO\")\nclassifier = pipeline(\"text-classification\", model='bhadresh-savani/distilbert-base-uncased-emotion',batch_size=550, return_all_scores=True,device=0)\n\ndef emotion_scores(words):\n    # print(words)\n    emotions = classifier(words)\n    # print(emotions[0])\n    return [[e['score'] for e in emotions[i]] for i in range(len(emotions))]\n\ndef generate_bigrams(corpus):\n    df=pd.read_csv(\"/kaggle/input/corpus/bigrams_left.csv\")\n    df=df[\"bigram_left\"]\n#     df=df[0:100]\n    \n    size=len(df)\n    return list(df[((div)*(size//8)):((div+1)*(size//8))])\n\nstart_time = time.time()\n\n\nbigrams = generate_bigrams(corpus)\n# print(len(bigrams))\n# exit(0)\n\n# Accumulate bigram data in a list\nbigram_input = bigrams\n# for bigram in bigrams:\n# #   # Combine bigram words into a single string\n#     bigram_text = \" \".join(bigram)\n#     # Append bigram data to the list\n#     bigram_input.append(bigram_text)\n\n#calculate emotions for all bigrams\nemotions = emotion_scores(bigram_input)\n\n# Process the bigram\nbigram_data=[]\nfor i in range(len(bigram_input)):\n    bigram_data.append([bigram_input[i]]+emotions[i])\n\n\n# Create a DataFrame for all bigrams\n","metadata":{"execution":{"iopub.status.busy":"2024-02-03T14:35:24.227660Z","iopub.execute_input":"2024-02-03T14:35:24.227933Z","iopub.status.idle":"2024-02-03T14:51:31.796779Z","shell.execute_reply.started":"2024-02-03T14:35:24.227905Z","shell.execute_reply":"2024-02-03T14:51:31.795751Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"INFO\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bhadresh-savani--distilbert-base-uncased-emotion/snapshots/5c2417f094aed91e6c1b0748888adb5839839eee/config.json\nModel config DistilBertConfig {\n  \"_name_or_path\": \"bhadresh-savani/distilbert-base-uncased-emotion\",\n  \"activation\": \"gelu\",\n  \"architectures\": [\n    \"DistilBertForSequenceClassification\"\n  ],\n  \"attention_dropout\": 0.1,\n  \"dim\": 768,\n  \"dropout\": 0.1,\n  \"hidden_dim\": 3072,\n  \"id2label\": {\n    \"0\": \"sadness\",\n    \"1\": \"joy\",\n    \"2\": \"love\",\n    \"3\": \"anger\",\n    \"4\": \"fear\",\n    \"5\": \"surprise\"\n  },\n  \"initializer_range\": 0.02,\n  \"label2id\": {\n    \"anger\": 3,\n    \"fear\": 4,\n    \"joy\": 1,\n    \"love\": 2,\n    \"sadness\": 0,\n    \"surprise\": 5\n  },\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"distilbert\",\n  \"n_heads\": 12,\n  \"n_layers\": 6,\n  \"pad_token_id\": 0,\n  \"qa_dropout\": 0.1,\n  \"seq_classif_dropout\": 0.2,\n  \"sinusoidal_pos_embds\": false,\n  \"tie_weights_\": true,\n  \"transformers_version\": \"4.37.0\",\n  \"vocab_size\": 30522\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bhadresh-savani--distilbert-base-uncased-emotion/snapshots/5c2417f094aed91e6c1b0748888adb5839839eee/config.json\nModel config DistilBertConfig {\n  \"_name_or_path\": \"bhadresh-savani/distilbert-base-uncased-emotion\",\n  \"activation\": \"gelu\",\n  \"architectures\": [\n    \"DistilBertForSequenceClassification\"\n  ],\n  \"attention_dropout\": 0.1,\n  \"dim\": 768,\n  \"dropout\": 0.1,\n  \"hidden_dim\": 3072,\n  \"id2label\": {\n    \"0\": \"sadness\",\n    \"1\": \"joy\",\n    \"2\": \"love\",\n    \"3\": \"anger\",\n    \"4\": \"fear\",\n    \"5\": \"surprise\"\n  },\n  \"initializer_range\": 0.02,\n  \"label2id\": {\n    \"anger\": 3,\n    \"fear\": 4,\n    \"joy\": 1,\n    \"love\": 2,\n    \"sadness\": 0,\n    \"surprise\": 5\n  },\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"distilbert\",\n  \"n_heads\": 12,\n  \"n_layers\": 6,\n  \"pad_token_id\": 0,\n  \"qa_dropout\": 0.1,\n  \"seq_classif_dropout\": 0.2,\n  \"sinusoidal_pos_embds\": false,\n  \"tie_weights_\": true,\n  \"transformers_version\": \"4.37.0\",\n  \"vocab_size\": 30522\n}\n\nloading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bhadresh-savani--distilbert-base-uncased-emotion/snapshots/5c2417f094aed91e6c1b0748888adb5839839eee/pytorch_model.bin\nAll model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n\nAll the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at bhadresh-savani/distilbert-base-uncased-emotion.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bhadresh-savani--distilbert-base-uncased-emotion/snapshots/5c2417f094aed91e6c1b0748888adb5839839eee/config.json\nModel config DistilBertConfig {\n  \"_name_or_path\": \"bhadresh-savani/distilbert-base-uncased-emotion\",\n  \"activation\": \"gelu\",\n  \"architectures\": [\n    \"DistilBertForSequenceClassification\"\n  ],\n  \"attention_dropout\": 0.1,\n  \"dim\": 768,\n  \"dropout\": 0.1,\n  \"hidden_dim\": 3072,\n  \"id2label\": {\n    \"0\": \"sadness\",\n    \"1\": \"joy\",\n    \"2\": \"love\",\n    \"3\": \"anger\",\n    \"4\": \"fear\",\n    \"5\": \"surprise\"\n  },\n  \"initializer_range\": 0.02,\n  \"label2id\": {\n    \"anger\": 3,\n    \"fear\": 4,\n    \"joy\": 1,\n    \"love\": 2,\n    \"sadness\": 0,\n    \"surprise\": 5\n  },\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"distilbert\",\n  \"n_heads\": 12,\n  \"n_layers\": 6,\n  \"pad_token_id\": 0,\n  \"qa_dropout\": 0.1,\n  \"seq_classif_dropout\": 0.2,\n  \"sinusoidal_pos_embds\": false,\n  \"tie_weights_\": true,\n  \"transformers_version\": \"4.37.0\",\n  \"vocab_size\": 30522\n}\n\nloading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bhadresh-savani--distilbert-base-uncased-emotion/snapshots/5c2417f094aed91e6c1b0748888adb5839839eee/vocab.txt\nloading file tokenizer.json from cache at None\nloading file added_tokens.json from cache at None\nloading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--bhadresh-savani--distilbert-base-uncased-emotion/snapshots/5c2417f094aed91e6c1b0748888adb5839839eee/special_tokens_map.json\nloading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bhadresh-savani--distilbert-base-uncased-emotion/snapshots/5c2417f094aed91e6c1b0748888adb5839839eee/tokenizer_config.json\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bhadresh-savani--distilbert-base-uncased-emotion/snapshots/5c2417f094aed91e6c1b0748888adb5839839eee/config.json\nModel config DistilBertConfig {\n  \"_name_or_path\": \"bhadresh-savani/distilbert-base-uncased-emotion\",\n  \"activation\": \"gelu\",\n  \"architectures\": [\n    \"DistilBertForSequenceClassification\"\n  ],\n  \"attention_dropout\": 0.1,\n  \"dim\": 768,\n  \"dropout\": 0.1,\n  \"hidden_dim\": 3072,\n  \"id2label\": {\n    \"0\": \"sadness\",\n    \"1\": \"joy\",\n    \"2\": \"love\",\n    \"3\": \"anger\",\n    \"4\": \"fear\",\n    \"5\": \"surprise\"\n  },\n  \"initializer_range\": 0.02,\n  \"label2id\": {\n    \"anger\": 3,\n    \"fear\": 4,\n    \"joy\": 1,\n    \"love\": 2,\n    \"sadness\": 0,\n    \"surprise\": 5\n  },\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"distilbert\",\n  \"n_heads\": 12,\n  \"n_layers\": 6,\n  \"pad_token_id\": 0,\n  \"qa_dropout\": 0.1,\n  \"seq_classif_dropout\": 0.2,\n  \"sinusoidal_pos_embds\": false,\n  \"tie_weights_\": true,\n  \"transformers_version\": \"4.37.0\",\n  \"vocab_size\": 30522\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bhadresh-savani--distilbert-base-uncased-emotion/snapshots/5c2417f094aed91e6c1b0748888adb5839839eee/config.json\nModel config DistilBertConfig {\n  \"_name_or_path\": \"bhadresh-savani/distilbert-base-uncased-emotion\",\n  \"activation\": \"gelu\",\n  \"architectures\": [\n    \"DistilBertForSequenceClassification\"\n  ],\n  \"attention_dropout\": 0.1,\n  \"dim\": 768,\n  \"dropout\": 0.1,\n  \"hidden_dim\": 3072,\n  \"id2label\": {\n    \"0\": \"sadness\",\n    \"1\": \"joy\",\n    \"2\": \"love\",\n    \"3\": \"anger\",\n    \"4\": \"fear\",\n    \"5\": \"surprise\"\n  },\n  \"initializer_range\": 0.02,\n  \"label2id\": {\n    \"anger\": 3,\n    \"fear\": 4,\n    \"joy\": 1,\n    \"love\": 2,\n    \"sadness\": 0,\n    \"surprise\": 5\n  },\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"distilbert\",\n  \"n_heads\": 12,\n  \"n_layers\": 6,\n  \"pad_token_id\": 0,\n  \"qa_dropout\": 0.1,\n  \"seq_classif_dropout\": 0.2,\n  \"sinusoidal_pos_embds\": false,\n  \"tie_weights_\": true,\n  \"transformers_version\": \"4.37.0\",\n  \"vocab_size\": 30522\n}\n\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:105: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"columns = [\"bigram\", \"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\ndf = pd.DataFrame(bigram_data, columns=columns)\n\n# Save the DataFrame to a CSV file\ndf.to_csv(f\"emotion_scores_bigrams_{div+1}.csv\", index=False)\n\nend_time = time.time()\nelapsed_time = end_time - start_time\n\n# # Print the result\nprint(f\"Elapsed time: {elapsed_time} seconds\")","metadata":{"execution":{"iopub.status.busy":"2024-02-03T14:51:31.798590Z","iopub.execute_input":"2024-02-03T14:51:31.798889Z","iopub.status.idle":"2024-02-03T14:52:09.245593Z","shell.execute_reply.started":"2024-02-03T14:51:31.798865Z","shell.execute_reply":"2024-02-03T14:52:09.244639Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Elapsed time: 1004.6644978523254 seconds\n","output_type":"stream"}]}]}