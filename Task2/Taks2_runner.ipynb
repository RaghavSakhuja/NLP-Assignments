{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from A1_T2_Q1_2021258_Q2_2021555 import BigramLM\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigram Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Karan Gupta 2021258**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bigram Model (No Smoothing)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1=BigramLM()\n",
    "b1.add_data(\"data\\corpus.txt\")\n",
    "b1.learn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rahul Oberoi 2021555**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Laplace and KneserNey Smoothing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b1.KneserNey_learn()\n",
    "# b1.Laplace_learn()\n",
    "b1.find_top5_bigrams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability Explanation for sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Karan Gupta 2021258**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:105: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"text-classification\", model='bhadresh-savani/distilbert-base-uncased-emotion', return_all_scores=True,device=0)\n",
    "def emotion_scores(words):\n",
    "    emotions = classifier(words)\n",
    "    return emotions[0]\n",
    "\n",
    "l={}\n",
    "emo=['anger','fear','joy','love','sadness','surprise']\n",
    "for i in emo:\n",
    "    with open(f\"Test/gen_{i}_Laplace.txt\",\"r\") as f:\n",
    "        s=f.readlines()[0].strip()\n",
    "        l[s]=i\n",
    "\n",
    "# l={'i action abandoning adrasteius involves end joan energy officer reilly results were ranted dan lamb contracts testimony alice achieved daughter parents':\"anger\",\"i potentially negative right acts was involved crises ambulatory i reluctant afraid\":\"fear\",\"i dip bloom experienced comparison everybodys tv nice f respecting beyond hang thanked\":\"joy\",\"i gentle enjoyed talking relations structure romantic starved such buffed shouldnt sensed laughed hart hairstye wise swear wedding lover riders kisses beloved romantically\":\"love\",\"i unfit learning emotional contain pathetic overly unsuccessful kenny but latter isolation circumstance remorse tackling toxins this beginning resigned tourists painless\":\"sadness\",\"i feel surprise isolation haunt rations amazingness figs editors experiment radiant unclear stic etc swamp path unusual\":\"surprise\"}\n",
    "# l_no={'i particular smell refusal negative viewed jason i record':\"anger\",\"i potentially negative right acts was involved crises ambulatory i reluctant afraid\":\"fear\",\"i radiator also feel fantastic snob wowed tell keenly i austen tales community taylor primer professional\":\"joy\",\"i feel birth soothing paternal under kisses twitter im smelling flirty passionate sony\":\"love\",}\n",
    "with open(\"evaluation.txt\",\"w\") as f:\n",
    "    for i in l:\n",
    "        print(type(i))\n",
    "        f.write(i+\"\\n\")\n",
    "        sentenceprob,bigramprob=b1.findsentenceprob(i,'Laplace')\n",
    "        f.write(f\"sentence prob:{sentenceprob} \\n\")\n",
    "        sen_score=emotion_scores(i)\n",
    "        for k in sen_score:\n",
    "            if k['label']==l[i]:\n",
    "                f.write(f\"sentence emotion score:{k} \\n\")\n",
    "\n",
    "        f.write(\"words emotion scores: \\n\")\n",
    "        words=i.split()\n",
    "        for j in range(len(words)-1):\n",
    "            score=emotion_scores(words[j]+\" \"+words[j+1])\n",
    "            for k in score:\n",
    "                if k['label']==l[i]:\n",
    "                    k['words']=words[j]+\" \"+words[j+1]\n",
    "                    k['bigramprob']=bigramprob[j]\n",
    "                    f.write(f\"{k}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extrinsic Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shivesh Gulati 2021286**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Smoothing Technique**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing_techniques=['No','Laplace','KneserNey']\n",
    "emotions=['anger','joy','love','fear','surprise','sadness']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the saved models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:288: UserWarning: Trying to unpickle estimator SVC from version 1.3.2 when using version 1.2.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:288: UserWarning: Trying to unpickle estimator LabelEncoder from version 1.3.2 when using version 1.2.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:288: UserWarning: Trying to unpickle estimator TfidfTransformer from version 1.3.2 when using version 1.2.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:288: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 1.3.2 when using version 1.2.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model,encoder,vectorizer = pickle.load(open(\"model.pk1\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoding the emotions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('anger', 0), ('joy', 2), ('love', 3), ('fear', 1), ('surprise', 5), ('sadness', 4)]\n"
     ]
    }
   ],
   "source": [
    "emotions_encoded = encoder.transform(emotions)\n",
    "mapping =[]\n",
    "for i in range(len(emotions)):\n",
    "    mapping.append((emotions[i],emotions_encoded[i]))\n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the text files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test(smoothing_technique):\n",
    "    x_test=[]\n",
    "    y_test=[]\n",
    "    for emotion in mapping:\n",
    "        f = open(f\"Test/gen_{emotion[0]}_{smoothing_technique}.txt\")\n",
    "        for line in f:\n",
    "            line = line[:-1]\n",
    "            x_test.append(line)\n",
    "            y_test.append(emotion[1])\n",
    "    x_test = vectorizer.transform(x_test)\n",
    "    return [x_test,y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting the accuracy scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for the model trained :-\n",
      "\n",
      "Metrics for No Smoothing\n",
      "Accuracy Score =  0.63\n",
      "Macro F1 Score =  0.6182748978204119\n",
      "\n",
      "Metrics for Laplace Smoothing\n",
      "Accuracy Score =  0.6766666666666666\n",
      "Macro F1 Score =  0.6761520851034918\n",
      "\n",
      "Metrics for KneserNey Smoothing\n",
      "Accuracy Score =  0.65\n",
      "Macro F1 Score =  0.6451522232775957\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for the model trained :-\")\n",
    "for smoothing_technique in smoothing_techniques:\n",
    "    x_test,y_test = create_test(smoothing_technique)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "    print(f\"\\nMetrics for {smoothing_technique} Smoothing\")\n",
    "    print(\"Accuracy Score = \",accuracy_score(y_test,y_test_pred))\n",
    "    print(\"Macro F1 Score = \",f1_score(y_test,y_test_pred,average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
