{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8101413,"sourceType":"datasetVersion","datasetId":4784361},{"sourceId":8156839,"sourceType":"datasetVersion","datasetId":4825218}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom datasets import load_dataset\nfrom transformers import (\n    RobertaTokenizerFast,\n    RobertaTokenizer,\n    RobertaForSequenceClassification,\n    TrainingArguments,\n    Trainer,\n    AutoConfig,\n)\n# from sklearnex import patch_sklearn\n# patch_sklearn()\n\nimport gc\nimport json\nimport pickle\nimport numpy as np    \nimport pandas as pd\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader\n\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:41:14.470568Z","iopub.execute_input":"2024-04-18T14:41:14.471179Z","iopub.status.idle":"2024-04-18T14:41:32.818059Z","shell.execute_reply.started":"2024-04-18T14:41:14.471146Z","shell.execute_reply":"2024-04-18T14:41:32.817131Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-04-18 14:41:24.967227: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-18 14:41:24.967323: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-18 14:41:25.088310: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/input/m2-dataset/modelM1_epoch10.pth\n/kaggle/input/m2-dataset/modelM1_epoch7.pth\n/kaggle/input/m2-dataset/modelM1_epoch5.pth\n/kaggle/input/m2-dataset/modelM1.pth\n/kaggle/input/m2-dataset/modelM1_epoch2.pth\n/kaggle/input/m2-dataset/modelM1_epoch1.pth\n/kaggle/input/m2-dataset/modelM1_epoch9.pth\n/kaggle/input/m2-dataset/modelM1_epoch6.pth\n/kaggle/input/m2-dataset/modelM1_epoch3.pth\n/kaggle/input/m2-dataset/tokenizerM1.pth\n/kaggle/input/m2-dataset/modelM1_epoch8.pth\n/kaggle/input/m2-dataset/modelM1_epoch4.pth\n/kaggle/input/emotion-dataset/train_file.json\n/kaggle/input/emotion-dataset/val_file.json\n","output_type":"stream"}]},{"cell_type":"code","source":"PATH='/kaggle/input/emotion-dataset/'\n# OUTPATH=''\n# PATH=\"data/\"\n# OUTPATH='output/'\nBATCH_SIZE=20\nMAX_LENGTH=128\nMAX_UTTERANCES=25\nEPOCHS=0\nEOS='</s>'\nSEP='[SEP]'\nSOS='<s>'\n\ntorch.manual_seed(0)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel_id = \"roberta-base\"\n# device=\"cpu\"\nlabel_encoding ={\n    'surprise':1,\n    'sadness':2,\n    'anger':3,\n    'fear':4,\n    'disgust':5,\n    'joy':6,\n    'neutral':0\n}","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:41:32.819844Z","iopub.execute_input":"2024-04-18T14:41:32.820415Z","iopub.status.idle":"2024-04-18T14:41:32.858795Z","shell.execute_reply.started":"2024-04-18T14:41:32.820387Z","shell.execute_reply":"2024-04-18T14:41:32.857944Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# read json\ndef get_data(file_path):\n    global label_encoding\n    with open(file_path) as f:\n        data = json.load(f)\n        # to pandas\n        df = pd.DataFrame(data)\n\n    sentence_len = []\n    text=[]\n    text_len=[]\n\n    for i in range(len(df)):\n        uterances=df.iloc[i]['utterances']\n        speaker=df.iloc[i]['speakers']\n        length=0\n        sentences=[]\n        for (speaker,uterance) in zip(speaker,uterances):\n            sentence=speaker+': '+uterance\n            sentences.append(sentence)\n            length+=len(uterance.split())\n        if(length==2):\n            print(sentence)\n            print(df.iloc[i])\n        sentence_len.append(length)\n        text_len.append(len(sentences))\n        text.append(sentences)\n        # print(length)\n        # break\n    y=[]\n    for i in df[\"emotions\"]:\n        lst=[]\n        for j in i:\n            lst.append(label_encoding[j])\n        if(len(lst)>MAX_UTTERANCES):\n            lst=lst[:MAX_UTTERANCES]\n        else:\n            lst.extend([-100]*(MAX_UTTERANCES-len(lst)))\n        y.append(lst)\n    x=[]\n    for i in text:\n        lst=[]\n        for j in i:\n            lst.append(j)\n        if(len(lst)>MAX_UTTERANCES):\n            lst=lst[:MAX_UTTERANCES]\n        else:\n            lst.extend([EOS]*(MAX_UTTERANCES-len(lst)))\n        # print(lst)\n        # print(len(lst))\n        x.append(lst)\n\n    # return x[:100],y[:100]\n    return x,y","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:41:32.859908Z","iopub.execute_input":"2024-04-18T14:41:32.860217Z","iopub.status.idle":"2024-04-18T14:41:32.873230Z","shell.execute_reply.started":"2024-04-18T14:41:32.860192Z","shell.execute_reply":"2024-04-18T14:41:32.872202Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# x_train, y_train = get_data(PATH+\"train_file.json\")\n# x_val, y_val = get_data(PATH+'val_file.json')","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:41:32.874344Z","iopub.execute_input":"2024-04-18T14:41:32.874616Z","iopub.status.idle":"2024-04-18T14:41:32.886542Z","shell.execute_reply.started":"2024-04-18T14:41:32.874594Z","shell.execute_reply":"2024-04-18T14:41:32.885582Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# ii=0\n# x_train[ii],y_train[ii]","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:41:32.889069Z","iopub.execute_input":"2024-04-18T14:41:32.889403Z","iopub.status.idle":"2024-04-18T14:41:32.896269Z","shell.execute_reply.started":"2024-04-18T14:41:32.889378Z","shell.execute_reply":"2024-04-18T14:41:32.895419Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from torch import nn\ntokenizer = RobertaTokenizer.from_pretrained(model_id)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:41:32.897355Z","iopub.execute_input":"2024-04-18T14:41:32.897692Z","iopub.status.idle":"2024-04-18T14:41:34.713673Z","shell.execute_reply.started":"2024-04-18T14:41:32.897662Z","shell.execute_reply":"2024-04-18T14:41:34.712868Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dc9e3c012c6461db355d2300c641c93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c9eed5be3af4e9289919ee271332252"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a7a41215eec4df590830fe590893ea8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dabf43929d0439693a46d63e6e4c1d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c79da1847ee44cd094d5630d685f18ab"}},"metadata":{}}]},{"cell_type":"code","source":"class Dataset(torch.utils.data.Dataset):\n    def __init__(self, data, tokenizer,labels):\n        self.data=data\n        self.tokenizer = tokenizer\n        self.labels = labels\n    \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):   \n        encoded_pair = self.tokenizer(self.data[idx],max_length=MAX_LENGTH,truncation=True,return_tensors=\"pt\",padding=\"max_length\")\n        # print(encoded_pair)\n        input_ids = encoded_pair['input_ids'].squeeze(0)\n        attention_mask = encoded_pair['attention_mask'].squeeze(0)\n        return input_ids,attention_mask,torch.tensor(self.labels[idx])","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:41:34.714737Z","iopub.execute_input":"2024-04-18T14:41:34.715028Z","iopub.status.idle":"2024-04-18T14:41:34.724116Z","shell.execute_reply.started":"2024-04-18T14:41:34.714996Z","shell.execute_reply":"2024-04-18T14:41:34.723157Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# train_dataset = Dataset(x_train,tokenizer,y_train)\n# val_dataset = Dataset(x_val,tokenizer,y_val)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:41:34.725203Z","iopub.execute_input":"2024-04-18T14:41:34.725456Z","iopub.status.idle":"2024-04-18T14:41:34.735592Z","shell.execute_reply.started":"2024-04-18T14:41:34.725434Z","shell.execute_reply":"2024-04-18T14:41:34.734721Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# for i in train_dataset:\n#     for j in i:\n#         print(len(j))\n#     break","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:41:34.736594Z","iopub.execute_input":"2024-04-18T14:41:34.736860Z","iopub.status.idle":"2024-04-18T14:41:34.745762Z","shell.execute_reply.started":"2024-04-18T14:41:34.736837Z","shell.execute_reply":"2024-04-18T14:41:34.744861Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# train_dataloader=DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=False)\n# val_dataloader=DataLoader(val_dataset,batch_size=BATCH_SIZE,shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:41:34.746703Z","iopub.execute_input":"2024-04-18T14:41:34.746934Z","iopub.status.idle":"2024-04-18T14:41:34.756369Z","shell.execute_reply.started":"2024-04-18T14:41:34.746914Z","shell.execute_reply":"2024-04-18T14:41:34.755443Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"\nclass EmotionClassifier(nn.Module):\n    def __init__(self, roberta_model, roberta_labels,num_labels):\n        super(EmotionClassifier, self).__init__()\n        self.roberta_labels = roberta_labels\n        self.num_labels = num_labels\n        self.roberta = roberta_model\n        self.roberta.requires_grad_(False)  \n        for param in self.roberta.roberta.encoder.layer[-3:].parameters():\n            param.requires_grad = True\n            \n#         self.LSTM = nn.LSTM(MAX_UTTERANCES*roberta_labels, 128, 2, batch_first=True)\n#         self.linear = nn.Linear(128, MAX_UTTERANCES*num_labels) \n        self.linear = nn.Linear(MAX_UTTERANCES*roberta_labels, MAX_UTTERANCES*num_labels)\n\n        \n    def forward(self, input_ids, attention_mask, token_type_ids=None):\n        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask,token_type_ids=token_type_ids)\n        output_logits=outputs.logits # output: (50,10)\n        batch_size = output_logits.shape[0]//MAX_UTTERANCES\n        output_logits=output_logits.view(batch_size,MAX_UTTERANCES*self.roberta_labels) # (2,25*10)\n        # print(\"OUTPUT: \",output_logits.shape) # now working correctly\n        \n        logits = self.linear(output_logits)\n        logits=logits.view(batch_size,MAX_UTTERANCES,self.num_labels)\n        # print(\"logits: \",logits.shape)\n        softmax_output = nn.functional.softmax(logits, dim=-1)\n        # print(\"softmax: \",softmax_output.shape)\n        return softmax_output\n    \nnum_labels = 7\nroberta_labels = 10\ndropout_prob = 0.07\nconfig = AutoConfig.from_pretrained(model_id)\nconfig.num_labels = roberta_labels\nconfig.hidden_dropout_prob = dropout_prob\nconfig.attention_probs_dropout_prob = dropout_prob\nroberta_model = RobertaForSequenceClassification.from_pretrained(model_id,config=config)\nmodel = EmotionClassifier(roberta_model,roberta_labels, num_labels)\nmodel.to(device)\noptimizer = torch.optim.AdamW(model.parameters(),lr=5e-5)\ncriterion = nn.functional.cross_entropy\n\n\n\ntrain_losses=[]\nval_losses=[]\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:41:34.757528Z","iopub.execute_input":"2024-04-18T14:41:34.757787Z","iopub.status.idle":"2024-04-18T14:41:37.454375Z","shell.execute_reply.started":"2024-04-18T14:41:34.757765Z","shell.execute_reply":"2024-04-18T14:41:37.453542Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a652e1fae5584dfa9c2d67cd0a49383f"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_epoch(model, optimizer,epoch):\n    model.train()\n    losses = 0\n    for batch in tqdm(train_dataloader, desc=f\"Epoch:{epoch}\",total=len(train_dataloader), leave=False):\n        input_ids = batch[0].to(device)\n        attention_mask = batch[1].to(device)\n        # token_type_ids = batch[2].to(device)\n        labels = batch[2].to(device)\n        # print(\"train: \",labels.shape,input_ids.shape,attention_mask.shape)\n        utterance_wise_batch={}\n        batch_size=input_ids.shape[0]\n        utterance_input_ids=input_ids.view(MAX_UTTERANCES*batch_size,-1)\n        utterance_attention_mask=attention_mask.view(MAX_UTTERANCES*batch_size,-1)\n        # for i in range(BATCH_SIZE):\n        #     for j in range(MAX_UTTERANCES):\n        #         utterance_input_ids.append(input_ids[i][j])\n        #         utterance_attention_mask.append(attention_mask[i][j])\n        # print(len(utterance_wise_batch),utterance_wise_batch[0])\n        # utterance_input_ids=torch.stack(utterance_input_ids)\n        # utterance_attention_mask=torch.stack(utterance_attention_mask)\n        utterance_wise_batch['input_ids']=utterance_input_ids\n        utterance_wise_batch['attention_mask']=utterance_attention_mask\n        # print(utterance_input_ids.shape,utterance_attention_mask.shape,len(utterance_wise_batch))\n        optimizer.zero_grad()\n        predicted = model(utterance_input_ids, utterance_attention_mask)\n        # print(\"lables: \",labels.shape)\n        predicted=predicted.view(-1,num_labels)\n        labels=labels.view(-1)\n        loss = criterion(predicted, labels)\n        losses += loss.item()\n        loss.backward()\n        optimizer.step()\n        del input_ids\n        del attention_mask\n        del labels\n        del predicted\n        del utterance_input_ids\n        del utterance_attention_mask\n        del utterance_wise_batch\n        gc.collect()\n        torch.cuda.empty_cache()\n        # break\n    x = losses / len(list(train_dataloader))\n    train_losses.append(x)\n#     wandb.log({'epoch':epoch,'train_loss':x})\n    tqdm.write(f\"Epoch:{epoch}, Avg Train Loss: {x}\")\n    gc.collect()\n    torch.cuda.empty_cache()\n    return x\n\n\n\ndef evaluate(model,val_dataloader,name):\n    with torch.no_grad():\n        model.eval()\n        losses = 0\n\n        all_labels = []\n        for batch in tqdm(val_dataloader, desc=name,total=len(val_dataloader), leave=False):\n            input_ids = batch[0].to(device)\n            attention_mask = batch[1].to(device)\n            labels = batch[2].to(device)\n            utterance_wise_batch={}\n            batch_size=input_ids.shape[0]\n            utterance_input_ids=input_ids.view(MAX_UTTERANCES*batch_size,-1)\n            utterance_attention_mask=attention_mask.view(MAX_UTTERANCES*batch_size,-1)\n            utterance_wise_batch['input_ids']=utterance_input_ids\n            utterance_wise_batch['attention_mask']=utterance_attention_mask\n            predicted = model(utterance_input_ids, utterance_attention_mask)\n            predicted=predicted.view(-1,num_labels)\n            labels=labels.view(-1)\n            loss = criterion(predicted, labels)\n            losses += loss.item()\n            predicted_labels = predicted.argmax(dim=-1)\n            all_labels.extend(predicted_labels.cpu().numpy())\n            del input_ids\n            del attention_mask\n            del labels\n            del predicted\n            del utterance_input_ids\n            del utterance_attention_mask\n            del utterance_wise_batch\n            gc.collect()\n            torch.cuda.empty_cache()\n            # break\n        x = losses / len(list(val_dataloader))\n        val_losses.append(x)\n        tqdm.write(f\"Avg {name} Loss: {x}\")\n        gc.collect()\n        torch.cuda.empty_cache()\n        return x, all_labels\n    \n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:41:37.455784Z","iopub.execute_input":"2024-04-18T14:41:37.456169Z","iopub.status.idle":"2024-04-18T14:41:37.473296Z","shell.execute_reply.started":"2024-04-18T14:41:37.456134Z","shell.execute_reply":"2024-04-18T14:41:37.472083Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"gc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:41:37.474508Z","iopub.execute_input":"2024-04-18T14:41:37.474829Z","iopub.status.idle":"2024-04-18T14:41:37.777604Z","shell.execute_reply.started":"2024-04-18T14:41:37.474795Z","shell.execute_reply":"2024-04-18T14:41:37.776577Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# gc.collect()\n# torch.cuda.empty_cache()\n# for epoch in range(1, EPOCHS+1):\n#     train_loss = train_epoch(model, optimizer,epoch)\n#     val_loss,all_labels = evaluate(model,val_dataloader=val_dataloader,name='Val')\n#     torch.save(model, f\"{OUTPATH}modelM1_epoch{epoch}.pth\")\n#     print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}\"))","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:41:37.781109Z","iopub.execute_input":"2024-04-18T14:41:37.781453Z","iopub.status.idle":"2024-04-18T14:41:37.788022Z","shell.execute_reply.started":"2024-04-18T14:41:37.781424Z","shell.execute_reply":"2024-04-18T14:41:37.787223Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# torch.save(model, f\"{OUTPATH}modelM1.pth\")\n# torch.save(tokenizer, f\"{OUTPATH}tokenizerM1.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:41:37.789058Z","iopub.execute_input":"2024-04-18T14:41:37.789353Z","iopub.status.idle":"2024-04-18T14:41:37.802047Z","shell.execute_reply.started":"2024-04-18T14:41:37.789319Z","shell.execute_reply":"2024-04-18T14:41:37.801282Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# train_losses,val_losses","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:41:37.803045Z","iopub.execute_input":"2024-04-18T14:41:37.803357Z","iopub.status.idle":"2024-04-18T14:41:37.812507Z","shell.execute_reply.started":"2024-04-18T14:41:37.803334Z","shell.execute_reply":"2024-04-18T14:41:37.811724Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# # plot losses\n# import matplotlib.pyplot as plt\n# plt.plot(train_losses,label='train')\n# plt.plot(val_losses,label='val')\n# plt.xlabel('Epochs')\n# plt.ylabel('Loss')\n# plt.title('Losses vs Epochs')\n# plt.legend()\n# plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:41:37.813554Z","iopub.execute_input":"2024-04-18T14:41:37.813819Z","iopub.status.idle":"2024-04-18T14:41:37.822335Z","shell.execute_reply.started":"2024-04-18T14:41:37.813797Z","shell.execute_reply":"2024-04-18T14:41:37.821460Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# load \nModel_path=\"/kaggle/input/m2-dataset/\"\nloaded_model = torch.load(f\"{Model_path}modelM1.pth\")\nloaded_tokenizer = torch.load(f\"{Model_path}tokenizerM1.pth\")\n\n# test\nx_test, y_test = get_data(PATH+'val_file.json')\ntest_dataset = Dataset(x_test,loaded_tokenizer,y_test)\ntest_dataloader=DataLoader(test_dataset,batch_size=BATCH_SIZE,shuffle=False)\ntest_loss,all_labels = evaluate(loaded_model,test_dataloader,name='Test')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:41:37.823377Z","iopub.execute_input":"2024-04-18T14:41:37.823691Z","iopub.status.idle":"2024-04-18T14:43:22.315896Z","shell.execute_reply.started":"2024-04-18T14:41:37.823662Z","shell.execute_reply":"2024-04-18T14:43:22.314971Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"                                                     \r","output_type":"stream"},{"name":"stdout","text":"Avg Test Loss: 1.3764947236970413\n","output_type":"stream"}]},{"cell_type":"code","source":"c = 0\nfor i in y_test:\n    c+=len(i)\nprint(c)\nprint(len(all_labels))","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:43:22.317315Z","iopub.execute_input":"2024-04-18T14:43:22.317672Z","iopub.status.idle":"2024-04-18T14:43:22.323469Z","shell.execute_reply.started":"2024-04-18T14:43:22.317640Z","shell.execute_reply":"2024-04-18T14:43:22.322442Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"21075\n21075\n","output_type":"stream"}]},{"cell_type":"code","source":"# print(y_test)\n# print(all_labels)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:43:22.324770Z","iopub.execute_input":"2024-04-18T14:43:22.325330Z","iopub.status.idle":"2024-04-18T14:43:22.336039Z","shell.execute_reply.started":"2024-04-18T14:43:22.325296Z","shell.execute_reply":"2024-04-18T14:43:22.335128Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"y_test_list = []\nfor i in y_test:\n    for j in i:\n        y_test_list.append(j)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:43:22.337182Z","iopub.execute_input":"2024-04-18T14:43:22.337452Z","iopub.status.idle":"2024-04-18T14:43:22.351119Z","shell.execute_reply.started":"2024-04-18T14:43:22.337431Z","shell.execute_reply":"2024-04-18T14:43:22.350234Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"print(f\"Test loss: {test_loss:.3f}\")\nf1_sccore = f1_score(y_test_list, all_labels, average='weighted')\nf1_macro = f1_score(y_test_list, all_labels, average='macro')\nprint(f1_macro,f1_sccore)\nprint(classification_report(y_test_list, all_labels))","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:43:22.352202Z","iopub.execute_input":"2024-04-18T14:43:22.352457Z","iopub.status.idle":"2024-04-18T14:43:22.445570Z","shell.execute_reply.started":"2024-04-18T14:43:22.352435Z","shell.execute_reply":"2024-04-18T14:43:22.444598Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Test loss: 1.376\n0.292763800084574 0.14283723740000193\n              precision    recall  f1-score   support\n\n        -100       0.00      0.00      0.00     13782\n           0       0.27      1.00      0.42      3200\n           1       0.38      0.85      0.52      1008\n           2       0.38      0.25      0.30       558\n           3       0.36      0.76      0.49       788\n           4       0.07      0.08      0.08       265\n           5       0.11      0.11      0.11       215\n           6       0.27      0.95      0.42      1259\n\n    accuracy                           0.29     21075\n   macro avg       0.23      0.50      0.29     21075\nweighted avg       0.10      0.29      0.14     21075\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"dic1={}\ndic2={}\nfor i in y_test_list:\n    if i in dic1:\n        dic1[i]+=1\n    else:\n        dic1[i]=1\n\nfor i in all_labels:\n    if i in dic2:\n        dic2[i]+=1\n    else:\n        dic2[i]=1\n\ndic1,dic2\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:43:22.446752Z","iopub.execute_input":"2024-04-18T14:43:22.447053Z","iopub.status.idle":"2024-04-18T14:43:22.474235Z","shell.execute_reply.started":"2024-04-18T14:43:22.447028Z","shell.execute_reply":"2024-04-18T14:43:22.473297Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"({3: 788, 0: 3200, 1: 1008, 5: 215, 4: 265, 2: 558, -100: 13782, 6: 1259},\n {1: 2276, 0: 11885, 3: 1653, 2: 367, 4: 313, 6: 4373, 5: 208})"},"metadata":{}}]},{"cell_type":"code","source":"p=[]\na=[]\nfor i in range(len(y_test_list)):\n    if(y_test_list[i]!=-100):\n        # print(y_test_list[i],preds[i])\n        p.append(all_labels[i])\n        a.append(y_test_list[i])\n\nprint(classification_report(a,p))\nf1_s=f1_score(a,p,average=None)\n\nfor label, f1 in enumerate(f1_s):\n    print(f\"F1 score for label {label}: {f1}\")\n\ndic1={}\ndic2={}\nfor i in range(len(p)):\n    if p[i] in dic1:\n        dic1[p[i]]+=1\n    else:\n        dic1[p[i]]=1\n    if a[i] in dic2:\n        dic2[a[i]]+=1\n    else:\n        dic2[a[i]]=1\n\ndic2,dic1\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:43:22.475432Z","iopub.execute_input":"2024-04-18T14:43:22.476252Z","iopub.status.idle":"2024-04-18T14:43:22.530102Z","shell.execute_reply.started":"2024-04-18T14:43:22.476227Z","shell.execute_reply":"2024-04-18T14:43:22.529246Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.83      1.00      0.91      3200\n           1       0.82      0.85      0.84      1008\n           2       0.93      0.25      0.39       558\n           3       0.81      0.76      0.78       788\n           4       1.00      0.08      0.15       265\n           5       0.96      0.11      0.19       215\n           6       0.80      0.95      0.87      1259\n\n    accuracy                           0.83      7293\n   macro avg       0.88      0.57      0.59      7293\nweighted avg       0.84      0.83      0.79      7293\n\nF1 score for label 0: 0.908806373595106\nF1 score for label 1: 0.8367546432062559\nF1 score for label 2: 0.39038189533239037\nF1 score for label 3: 0.7819843342036553\nF1 score for label 4: 0.15331010452961671\nF1 score for label 5: 0.19246861924686195\nF1 score for label 6: 0.8681718863801894\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"({3: 788, 0: 3200, 1: 1008, 5: 215, 4: 265, 2: 558, 6: 1259},\n {1: 1038, 0: 3829, 3: 744, 2: 149, 6: 1487, 5: 24, 4: 22})"},"metadata":{}}]}]}