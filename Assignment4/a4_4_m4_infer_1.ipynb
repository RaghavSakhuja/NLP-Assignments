{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T23:02:06.487536Z","iopub.status.busy":"2024-04-16T23:02:06.486913Z","iopub.status.idle":"2024-04-16T23:02:06.491390Z","shell.execute_reply":"2024-04-16T23:02:06.490449Z","shell.execute_reply.started":"2024-04-16T23:02:06.487505Z"},"papermill":{"duration":13.62755,"end_time":"2024-04-16T07:14:21.542435","exception":false,"start_time":"2024-04-16T07:14:07.914885","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# ! pip install sentence-transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T23:02:06.496070Z","iopub.status.busy":"2024-04-16T23:02:06.495766Z","iopub.status.idle":"2024-04-16T23:02:06.505870Z","shell.execute_reply":"2024-04-16T23:02:06.505197Z","shell.execute_reply.started":"2024-04-16T23:02:06.496046Z"},"papermill":{"duration":18.958755,"end_time":"2024-04-16T07:14:40.510748","exception":false,"start_time":"2024-04-16T07:14:21.551993","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n","\n"]}],"source":["import torch\n","from torch import nn\n","from datasets import load_dataset\n","from transformers import (\n","    RobertaTokenizer,\n","    RobertaForSequenceClassification,\n","    TrainingArguments,\n","    Trainer,\n","    AutoConfig,\n",")\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","# from sklearnex import patch_sklearn\n","# patch_sklearn()\n","# from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n","from torch.utils.data import Dataset, DataLoader\n","\n","import gc\n","import json\n","import pickle\n","import numpy as np    \n","import pandas as pd\n","# from tqdm.notebook import tqdm\n","from tqdm import tqdm\n","from sklearn.metrics import accuracy_score, f1_score, classification_report\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[],"source":["# /kaggle/input/emotion-dataset/train_file.json"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T23:02:56.761770Z","iopub.status.busy":"2024-04-16T23:02:56.761166Z","iopub.status.idle":"2024-04-16T23:02:56.800664Z","shell.execute_reply":"2024-04-16T23:02:56.799893Z","shell.execute_reply.started":"2024-04-16T23:02:56.761725Z"},"papermill":{"duration":0.072165,"end_time":"2024-04-16T07:14:40.592219","exception":false,"start_time":"2024-04-16T07:14:40.520054","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# PATH=\"/kaggle/input/\"\n","# OUTPATH='/kaggle/working/'\n","# PATH=\"D:\\\\ghd\\\\NLP-Assignments\\\\Assignment4\\\\data\\\\\"\n","PATH=\"data/\"\n","OUTPATH='output/'\n","BATCH_SIZE=512\n","MAX_LENGTH=256\n","MAX_UTTERANCES=24\n","ROBERTA_LABELS=100\n","EPOCHS=0\n","EOS='</s>'\n","SEP='[SEP]'\n","# SOS='o'\n","\n","torch.manual_seed(0)\n","\n","model_id = \"roberta-base\""]},{"cell_type":"code","execution_count":5,"id":"c5bdf417","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["NVIDIA GeForce RTX 3060 Laptop GPU\n"]},{"data":{"text/plain":["device(type='cuda')"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["device = \"\"\n","if torch.cuda.is_available():\n","    device = \"cuda\"\n","    print(torch.cuda.get_device_name(0))\n","else:\n","    device = \"cpu\"\n","\n","device = torch.device(device)\n","device"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T23:03:03.867687Z","iopub.status.busy":"2024-04-16T23:03:03.866822Z","iopub.status.idle":"2024-04-16T23:03:04.408531Z","shell.execute_reply":"2024-04-16T23:03:04.407756Z","shell.execute_reply.started":"2024-04-16T23:03:03.867656Z"},"papermill":{"duration":0.292904,"end_time":"2024-04-16T07:14:40.894359","exception":false,"start_time":"2024-04-16T07:14:40.601455","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["pad=-100\n","def get_train(data):\n","    x=[]\n","    y=[]\n","    for row in data:\n","        speakers=row['speakers']\n","        emotions=row['emotions']\n","        utterances=row['utterances']\n","        triggers=row['triggers']\n","        # print(speakers,emotions,utterances)\n","        # trim in front\n","        while len(utterances)>MAX_UTTERANCES:\n","            utterances.pop(0)\n","            speakers.pop(0)\n","            emotions.pop(0)\n","            triggers.pop(0)\n","        \n","        # print(speakers,emotions,utterances)\n","        # pad\n","        while len(utterances)<MAX_UTTERANCES:\n","            utterances.insert(0,EOS)\n","            speakers.insert(0,EOS)\n","            emotions.insert(0,EOS)\n","            triggers.insert(0,-100)\n","        # print(speakers[1],emotions[1],utterances[1])\n","        t=\"\"\n","        s1=[]\n","        s2=[]        \n","        for i in range(MAX_UTTERANCES):\n","            if(utterances[i]==EOS):\n","                s1.append(utterances[i])\n","                s2.append(utterances[i])\n","                t=EOS\n","                continue\n","            if(t==EOS):\n","                t=\"\"\n","            # text.append([t,f\"{speakers[-1]}:{utterances[-1]}:{emotions[-1]}\"])\n","            s1.append(t)\n","            s2.append(f\"{speakers[-1]}:{utterances[-1]}:{emotions[-1]}\")\n","\n","            t+=f\"{speakers[i]}:{utterances[i]}:{emotions[i]} \"\n","        x.append([s1,s2])\n","        trigs=[]\n","        for i in triggers:\n","            if(i is None):\n","                trigs.append(0)\n","            else:\n","                trigs.append(int(i))\n","        y.append(trigs)\n","    \n","    return x,y\n","\n","def get_eval(data):\n","    x=[]\n","    y=[]\n","    max_len=max([len(i[\"triggers\"]) for i in data])\n","    # left pad triggers\n","\n","    for row in data:\n","        speakers=row['speakers']\n","        emotions=row['emotions']\n","        utterances=row['utterances']\n","        triggers=row['triggers']\n","        # trim in front\n","        while len(triggers)>max_len:\n","            triggers.pop(0)\n","        # left pad triggers\n","        while len(triggers)<max_len:\n","            triggers.insert(0,-100)\n","\n","\n","        # print(speakers,emotions,utterances)\n","        # trim in front\n","        while len(utterances)>MAX_UTTERANCES:\n","            utterances.pop(0)\n","            speakers.pop(0)\n","            emotions.pop(0)\n","        \n","        # print(speakers,emotions,utterances)\n","        # pad\n","        while len(utterances)<MAX_UTTERANCES:\n","            utterances.insert(0,EOS)\n","            speakers.insert(0,EOS)\n","            emotions.insert(0,EOS)\n","        # print(speakers[1],emotions[1],utterances[1])\n","        s1=[]\n","        s2=[]\n","        t=\"\"\n","        for i in range(MAX_UTTERANCES):\n","            if(utterances[i]==EOS):\n","                s1.append(utterances[i])\n","                s2.append(utterances[i])\n","                t=EOS\n","                continue\n","            if(t==EOS):\n","                t=\"\"\n","            # text.append([t,f\"{speakers[-1]}:{utterances[-1]}:{emotions[-1]}\"])\n","            s1.append(t)\n","            s2.append(f\"{speakers[-1]}:{utterances[-1]}:{emotions[-1]}\")\n","            t+=f\"{speakers[i]}:{utterances[i]}:{emotions[i]} \"\n","        x.append([s1,s2])\n","        trigs=[]\n","        for i in triggers:\n","            if(i is None):\n","                trigs.append(0)\n","            else:\n","                trigs.append(int(i))\n","        y.append(trigs)\n","    \n","    return x,y\n","\n","\n","def load_data(PATH):\n","    with open(PATH) as f:\n","        data = json.load(f)\n","        return data\n","    \n","label_encoding = {\n","    \"S\":0,\n","    \"surprise\":1,\n","    \"fear\":2,\n","    \"neutral\":3,\n","    \"sadness\":4,\n","    \"disgust\":5,\n","    \"anger\":6,\n","    \"joy\":7\n","}\n"]},{"cell_type":"code","execution_count":7,"id":"6de741a0","metadata":{},"outputs":[],"source":["\n","data = load_data(PATH+\"train_file.json\")\n","data_val = load_data(PATH+\"val_file.json\")\n","x_train,y_train = get_train(data)\n","x_val,y_val = get_train(data_val)"]},{"cell_type":"code","execution_count":8,"id":"1467601c","metadata":{},"outputs":[{"data":{"text/plain":["([['</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '',\n","   'Phoebe:You-you\\x85you had sex with Ursula?!:surprise ',\n","   'Phoebe:You-you\\x85you had sex with Ursula?!:surprise Eric:Uh, a little bit. She-she-she walked in and I thought she was you and I kissed her and:fear ',\n","   \"Phoebe:You-you\\x85you had sex with Ursula?!:surprise Eric:Uh, a little bit. She-she-she walked in and I thought she was you and I kissed her and:fear Phoebe:You didn't notice she was wearing different clothes?!:surprise \",\n","   \"Phoebe:You-you\\x85you had sex with Ursula?!:surprise Eric:Uh, a little bit. She-she-she walked in and I thought she was you and I kissed her and:fear Phoebe:You didn't notice she was wearing different clothes?!:surprise Eric:Well I was just so excited to see you.:sadness \"],\n","  ['</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   \"Phoebe:Oh. Ew! Ew! Ew! Ugh! Y'know what? This is too weird.:disgust\",\n","   \"Phoebe:Oh. Ew! Ew! Ew! Ugh! Y'know what? This is too weird.:disgust\",\n","   \"Phoebe:Oh. Ew! Ew! Ew! Ugh! Y'know what? This is too weird.:disgust\",\n","   \"Phoebe:Oh. Ew! Ew! Ew! Ugh! Y'know what? This is too weird.:disgust\",\n","   \"Phoebe:Oh. Ew! Ew! Ew! Ugh! Y'know what? This is too weird.:disgust\"]],\n"," [-100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  1,\n","  1,\n","  0,\n","  0,\n","  0])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["x_train[0],y_train[0]"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T23:03:08.393119Z","iopub.status.busy":"2024-04-16T23:03:08.392278Z","iopub.status.idle":"2024-04-16T23:03:08.549784Z","shell.execute_reply":"2024-04-16T23:03:08.548948Z","shell.execute_reply.started":"2024-04-16T23:03:08.393088Z"},"papermill":{"duration":0.021067,"end_time":"2024-04-16T07:14:40.926900","exception":false,"start_time":"2024-04-16T07:14:40.905833","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["263\n"]}],"source":["max_len=0\n","for i in range(len(x_train)):\n","    for j in range(len(x_train[i][0])):\n","        max_len=max(max_len,len(x_train[i][0][j].split())+len(x_train[i][1][j].split()))\n","print(max_len)\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T23:03:13.783385Z","iopub.status.busy":"2024-04-16T23:03:13.782605Z","iopub.status.idle":"2024-04-16T23:03:13.791148Z","shell.execute_reply":"2024-04-16T23:03:13.790170Z","shell.execute_reply.started":"2024-04-16T23:03:13.783352Z"},"trusted":true},"outputs":[{"data":{"text/plain":["([['</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '',\n","   'Chandler:Hey! Hold on a minute, hold on a second. Do you think these pearls are nice?:anger ',\n","   \"Chandler:Hey! Hold on a minute, hold on a second. Do you think these pearls are nice?:anger Joey:I'd really prefer a mountain bike.:neutral \",\n","   \"Chandler:Hey! Hold on a minute, hold on a second. Do you think these pearls are nice?:anger Joey:I'd really prefer a mountain bike.:neutral Chandler:Janice's birthday is coming up, I want to get her something speacial. Come in here with me.:neutral \",\n","   \"Chandler:Hey! Hold on a minute, hold on a second. Do you think these pearls are nice?:anger Joey:I'd really prefer a mountain bike.:neutral Chandler:Janice's birthday is coming up, I want to get her something speacial. Come in here with me.:neutral Joey:Whoa, whoa, whoa, wait, whoa.:surprise \",\n","   \"Chandler:Hey! Hold on a minute, hold on a second. Do you think these pearls are nice?:anger Joey:I'd really prefer a mountain bike.:neutral Chandler:Janice's birthday is coming up, I want to get her something speacial. Come in here with me.:neutral Joey:Whoa, whoa, whoa, wait, whoa.:surprise Joey:Do you ah, want to get her something speacial, get her flowers, get her candy, get her gum, girls love gum.:anger \",\n","   \"Chandler:Hey! Hold on a minute, hold on a second. Do you think these pearls are nice?:anger Joey:I'd really prefer a mountain bike.:neutral Chandler:Janice's birthday is coming up, I want to get her something speacial. Come in here with me.:neutral Joey:Whoa, whoa, whoa, wait, whoa.:surprise Joey:Do you ah, want to get her something speacial, get her flowers, get her candy, get her gum, girls love gum.:anger Chandler:That's a good idea, \\x91Dear Janice have a Hubba-Bubba birthday'. I would like to get her something serious.:disgust \",\n","   \"Chandler:Hey! Hold on a minute, hold on a second. Do you think these pearls are nice?:anger Joey:I'd really prefer a mountain bike.:neutral Chandler:Janice's birthday is coming up, I want to get her something speacial. Come in here with me.:neutral Joey:Whoa, whoa, whoa, wait, whoa.:surprise Joey:Do you ah, want to get her something speacial, get her flowers, get her candy, get her gum, girls love gum.:anger Chandler:That's a good idea, \\x91Dear Janice have a Hubba-Bubba birthday'. I would like to get her something serious.:disgust Joey:Oh, you want something serious.:neutral \",\n","   \"Chandler:Hey! Hold on a minute, hold on a second. Do you think these pearls are nice?:anger Joey:I'd really prefer a mountain bike.:neutral Chandler:Janice's birthday is coming up, I want to get her something speacial. Come in here with me.:neutral Joey:Whoa, whoa, whoa, wait, whoa.:surprise Joey:Do you ah, want to get her something speacial, get her flowers, get her candy, get her gum, girls love gum.:anger Chandler:That's a good idea, \\x91Dear Janice have a Hubba-Bubba birthday'. I would like to get her something serious.:disgust Joey:Oh, you want something serious.:neutral Joey:Y'know what you should do, you should get her one of those um, barium enemas.:neutral \",\n","   \"Chandler:Hey! Hold on a minute, hold on a second. Do you think these pearls are nice?:anger Joey:I'd really prefer a mountain bike.:neutral Chandler:Janice's birthday is coming up, I want to get her something speacial. Come in here with me.:neutral Joey:Whoa, whoa, whoa, wait, whoa.:surprise Joey:Do you ah, want to get her something speacial, get her flowers, get her candy, get her gum, girls love gum.:anger Chandler:That's a good idea, \\x91Dear Janice have a Hubba-Bubba birthday'. I would like to get her something serious.:disgust Joey:Oh, you want something serious.:neutral Joey:Y'know what you should do, you should get her one of those um, barium enemas.:neutral Joey:Those are dead serious.:neutral \",\n","   \"Chandler:Hey! Hold on a minute, hold on a second. Do you think these pearls are nice?:anger Joey:I'd really prefer a mountain bike.:neutral Chandler:Janice's birthday is coming up, I want to get her something speacial. Come in here with me.:neutral Joey:Whoa, whoa, whoa, wait, whoa.:surprise Joey:Do you ah, want to get her something speacial, get her flowers, get her candy, get her gum, girls love gum.:anger Chandler:That's a good idea, \\x91Dear Janice have a Hubba-Bubba birthday'. I would like to get her something serious.:disgust Joey:Oh, you want something serious.:neutral Joey:Y'know what you should do, you should get her one of those um, barium enemas.:neutral Joey:Those are dead serious.:neutral Chandler:All right. Look, I'm gonna go in here, and you don't buy me anything ever.:anger \",\n","   \"Chandler:Hey! Hold on a minute, hold on a second. Do you think these pearls are nice?:anger Joey:I'd really prefer a mountain bike.:neutral Chandler:Janice's birthday is coming up, I want to get her something speacial. Come in here with me.:neutral Joey:Whoa, whoa, whoa, wait, whoa.:surprise Joey:Do you ah, want to get her something speacial, get her flowers, get her candy, get her gum, girls love gum.:anger Chandler:That's a good idea, \\x91Dear Janice have a Hubba-Bubba birthday'. I would like to get her something serious.:disgust Joey:Oh, you want something serious.:neutral Joey:Y'know what you should do, you should get her one of those um, barium enemas.:neutral Joey:Those are dead serious.:neutral Chandler:All right. Look, I'm gonna go in here, and you don't buy me anything ever.:anger Joey:No, no, you can't, you can't, okay, you can't, you can't buy her pearls, you just can't, you can't, you can't.:fear \",\n","   \"Chandler:Hey! Hold on a minute, hold on a second. Do you think these pearls are nice?:anger Joey:I'd really prefer a mountain bike.:neutral Chandler:Janice's birthday is coming up, I want to get her something speacial. Come in here with me.:neutral Joey:Whoa, whoa, whoa, wait, whoa.:surprise Joey:Do you ah, want to get her something speacial, get her flowers, get her candy, get her gum, girls love gum.:anger Chandler:That's a good idea, \\x91Dear Janice have a Hubba-Bubba birthday'. I would like to get her something serious.:disgust Joey:Oh, you want something serious.:neutral Joey:Y'know what you should do, you should get her one of those um, barium enemas.:neutral Joey:Those are dead serious.:neutral Chandler:All right. Look, I'm gonna go in here, and you don't buy me anything ever.:anger Joey:No, no, you can't, you can't, okay, you can't, you can't buy her pearls, you just can't, you can't, you can't.:fear Chandler:Why not?!:surprise \",\n","   \"Chandler:Hey! Hold on a minute, hold on a second. Do you think these pearls are nice?:anger Joey:I'd really prefer a mountain bike.:neutral Chandler:Janice's birthday is coming up, I want to get her something speacial. Come in here with me.:neutral Joey:Whoa, whoa, whoa, wait, whoa.:surprise Joey:Do you ah, want to get her something speacial, get her flowers, get her candy, get her gum, girls love gum.:anger Chandler:That's a good idea, \\x91Dear Janice have a Hubba-Bubba birthday'. I would like to get her something serious.:disgust Joey:Oh, you want something serious.:neutral Joey:Y'know what you should do, you should get her one of those um, barium enemas.:neutral Joey:Those are dead serious.:neutral Chandler:All right. Look, I'm gonna go in here, and you don't buy me anything ever.:anger Joey:No, no, you can't, you can't, okay, you can't, you can't buy her pearls, you just can't, you can't, you can't.:fear Chandler:Why not?!:surprise Joey:Oh God. Uh, okay, here's the thing, this is the thing, okay, the thing is...:neutral \",\n","   \"Chandler:Hey! Hold on a minute, hold on a second. Do you think these pearls are nice?:anger Joey:I'd really prefer a mountain bike.:neutral Chandler:Janice's birthday is coming up, I want to get her something speacial. Come in here with me.:neutral Joey:Whoa, whoa, whoa, wait, whoa.:surprise Joey:Do you ah, want to get her something speacial, get her flowers, get her candy, get her gum, girls love gum.:anger Chandler:That's a good idea, \\x91Dear Janice have a Hubba-Bubba birthday'. I would like to get her something serious.:disgust Joey:Oh, you want something serious.:neutral Joey:Y'know what you should do, you should get her one of those um, barium enemas.:neutral Joey:Those are dead serious.:neutral Chandler:All right. Look, I'm gonna go in here, and you don't buy me anything ever.:anger Joey:No, no, you can't, you can't, okay, you can't, you can't buy her pearls, you just can't, you can't, you can't.:fear Chandler:Why not?!:surprise Joey:Oh God. Uh, okay, here's the thing, this is the thing, okay, the thing is...:neutral Chandler:What is the thing?:sadness \",\n","   \"Chandler:Hey! Hold on a minute, hold on a second. Do you think these pearls are nice?:anger Joey:I'd really prefer a mountain bike.:neutral Chandler:Janice's birthday is coming up, I want to get her something speacial. Come in here with me.:neutral Joey:Whoa, whoa, whoa, wait, whoa.:surprise Joey:Do you ah, want to get her something speacial, get her flowers, get her candy, get her gum, girls love gum.:anger Chandler:That's a good idea, \\x91Dear Janice have a Hubba-Bubba birthday'. I would like to get her something serious.:disgust Joey:Oh, you want something serious.:neutral Joey:Y'know what you should do, you should get her one of those um, barium enemas.:neutral Joey:Those are dead serious.:neutral Chandler:All right. Look, I'm gonna go in here, and you don't buy me anything ever.:anger Joey:No, no, you can't, you can't, okay, you can't, you can't buy her pearls, you just can't, you can't, you can't.:fear Chandler:Why not?!:surprise Joey:Oh God. Uh, okay, here's the thing, this is the thing, okay, the thing is...:neutral Chandler:What is the thing?:sadness Joey:Okay. I went down to the \\x91Mattress King' showroom and, and I saw Janice, kissing her ex-husband.:sadness \",\n","   \"Chandler:Hey! Hold on a minute, hold on a second. Do you think these pearls are nice?:anger Joey:I'd really prefer a mountain bike.:neutral Chandler:Janice's birthday is coming up, I want to get her something speacial. Come in here with me.:neutral Joey:Whoa, whoa, whoa, wait, whoa.:surprise Joey:Do you ah, want to get her something speacial, get her flowers, get her candy, get her gum, girls love gum.:anger Chandler:That's a good idea, \\x91Dear Janice have a Hubba-Bubba birthday'. I would like to get her something serious.:disgust Joey:Oh, you want something serious.:neutral Joey:Y'know what you should do, you should get her one of those um, barium enemas.:neutral Joey:Those are dead serious.:neutral Chandler:All right. Look, I'm gonna go in here, and you don't buy me anything ever.:anger Joey:No, no, you can't, you can't, okay, you can't, you can't buy her pearls, you just can't, you can't, you can't.:fear Chandler:Why not?!:surprise Joey:Oh God. Uh, okay, here's the thing, this is the thing, okay, the thing is...:neutral Chandler:What is the thing?:sadness Joey:Okay. I went down to the \\x91Mattress King' showroom and, and I saw Janice, kissing her ex-husband.:sadness Chandler:What?:surprise \"],\n","  ['</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   '</s>',\n","   'Joey:They were in his office.:neutral',\n","   'Joey:They were in his office.:neutral',\n","   'Joey:They were in his office.:neutral',\n","   'Joey:They were in his office.:neutral',\n","   'Joey:They were in his office.:neutral',\n","   'Joey:They were in his office.:neutral',\n","   'Joey:They were in his office.:neutral',\n","   'Joey:They were in his office.:neutral',\n","   'Joey:They were in his office.:neutral',\n","   'Joey:They were in his office.:neutral',\n","   'Joey:They were in his office.:neutral',\n","   'Joey:They were in his office.:neutral',\n","   'Joey:They were in his office.:neutral',\n","   'Joey:They were in his office.:neutral',\n","   'Joey:They were in his office.:neutral',\n","   'Joey:They were in his office.:neutral',\n","   'Joey:They were in his office.:neutral']],\n"," [-100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  1,\n","  0])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["x_val[0],y_val[0]"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T23:03:17.310035Z","iopub.status.busy":"2024-04-16T23:03:17.309436Z","iopub.status.idle":"2024-04-16T23:03:17.541524Z","shell.execute_reply":"2024-04-16T23:03:17.540441Z","shell.execute_reply.started":"2024-04-16T23:03:17.310001Z"},"papermill":{"duration":0.211152,"end_time":"2024-04-16T07:14:41.150361","exception":false,"start_time":"2024-04-16T07:14:40.939209","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# np.array(x_train).shape"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T23:03:21.202092Z","iopub.status.busy":"2024-04-16T23:03:21.201719Z","iopub.status.idle":"2024-04-16T23:03:21.208509Z","shell.execute_reply":"2024-04-16T23:03:21.207651Z","shell.execute_reply.started":"2024-04-16T23:03:21.202065Z"},"papermill":{"duration":0.020997,"end_time":"2024-04-16T07:14:41.183208","exception":false,"start_time":"2024-04-16T07:14:41.162211","status":"completed"},"tags":[],"trusted":true},"outputs":[{"data":{"text/plain":["(6740, 6740, 843, 843)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["len(x_train),len(y_train),len(x_val),len(y_val)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T23:03:23.553092Z","iopub.status.busy":"2024-04-16T23:03:23.552704Z","iopub.status.idle":"2024-04-16T23:03:25.231134Z","shell.execute_reply":"2024-04-16T23:03:25.230352Z","shell.execute_reply.started":"2024-04-16T23:03:23.553063Z"},"papermill":{"duration":9.818453,"end_time":"2024-04-16T07:14:51.047224","exception":false,"start_time":"2024-04-16T07:14:41.228771","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["tokenizer = RobertaTokenizer.from_pretrained(model_id)"]},{"cell_type":"code","execution_count":14,"metadata":{"papermill":{"duration":0.019649,"end_time":"2024-04-16T07:14:51.080058","exception":false,"start_time":"2024-04-16T07:14:51.060409","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# class"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T23:03:27.046185Z","iopub.status.busy":"2024-04-16T23:03:27.045366Z","iopub.status.idle":"2024-04-16T23:03:27.052247Z","shell.execute_reply":"2024-04-16T23:03:27.051384Z","shell.execute_reply.started":"2024-04-16T23:03:27.046153Z"},"papermill":{"duration":0.021695,"end_time":"2024-04-16T07:14:51.114506","exception":false,"start_time":"2024-04-16T07:14:51.092811","status":"completed"},"tags":[],"trusted":true},"outputs":[{"data":{"text/plain":["([-100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  1,\n","  1,\n","  0,\n","  0,\n","  0],\n"," [-100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  -100,\n","  0,\n","  0,\n","  1])"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# len(x_train)\n","# len(x_train[0])\n","# x_train = np.array(x_train)\n","# x_train\n","y_train[0],y_train[4]"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T23:03:37.191062Z","iopub.status.busy":"2024-04-16T23:03:37.190339Z","iopub.status.idle":"2024-04-16T23:03:37.197677Z","shell.execute_reply":"2024-04-16T23:03:37.196743Z","shell.execute_reply.started":"2024-04-16T23:03:37.191030Z"},"papermill":{"duration":0.022027,"end_time":"2024-04-16T07:14:51.149403","exception":false,"start_time":"2024-04-16T07:14:51.127376","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class Dataset(Dataset):\n","    def __init__(self, data, tokenizer,labels):\n","        self.data = data\n","        self.tokenizer = tokenizer\n","        self.labels = labels\n","        \n","    def __len__(self):\n","        return len(self.data)\n","    \n","    def __getitem__(self,idx):\n","#         print(self.data[idx])\n","#         dat = \"\".join(self.data[idx])\n","        s1,s2 = self.data[idx][0],self.data[idx][1]\n","        s1_tokenized = self.tokenizer(s1,max_length=MAX_LENGTH,truncation=True,return_tensors=\"pt\",padding=\"max_length\")\n","        s2_tokenized = self.tokenizer(s2,max_length=MAX_LENGTH,truncation=True,return_tensors=\"pt\",padding=\"max_length\")\n","        input_ids = torch.cat((s1_tokenized[\"input_ids\"],s2_tokenized[\"input_ids\"]),dim=1).squeeze(0)\n","        # x_tokenized = self.tokenizer(self.data[idx],max_length=MAX_LENGTH,truncation=True,return_tensors=\"pt\",padding=\"max_length\")\n","        # input_ids = x_tokenized[\"input_ids\"].squeeze(0)\n","        # attention_mask = x_tokenized[\"attention_mask\"].squeeze(0)\n","        return input_ids,torch.tensor(self.labels[idx]).squeeze(0)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T23:03:39.120557Z","iopub.status.busy":"2024-04-16T23:03:39.119849Z","iopub.status.idle":"2024-04-16T23:03:39.124758Z","shell.execute_reply":"2024-04-16T23:03:39.123817Z","shell.execute_reply.started":"2024-04-16T23:03:39.120526Z"},"papermill":{"duration":0.019947,"end_time":"2024-04-16T07:14:51.182032","exception":false,"start_time":"2024-04-16T07:14:51.162085","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["train_dataset = Dataset(x_train,tokenizer,y_train)\n","val_dataset = Dataset(x_val,tokenizer,y_val)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T23:03:41.719843Z","iopub.status.busy":"2024-04-16T23:03:41.719136Z","iopub.status.idle":"2024-04-16T23:03:41.777385Z","shell.execute_reply":"2024-04-16T23:03:41.776491Z","shell.execute_reply.started":"2024-04-16T23:03:41.719810Z"},"papermill":{"duration":0.042645,"end_time":"2024-04-16T07:14:51.237543","exception":false,"start_time":"2024-04-16T07:14:51.194898","status":"completed"},"tags":[],"trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([24, 512])"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset[0][0].shape"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T23:03:44.573889Z","iopub.status.busy":"2024-04-16T23:03:44.573538Z","iopub.status.idle":"2024-04-16T23:03:44.579905Z","shell.execute_reply":"2024-04-16T23:03:44.578989Z","shell.execute_reply.started":"2024-04-16T23:03:44.573861Z"},"papermill":{"duration":0.020869,"end_time":"2024-04-16T07:14:51.271759","exception":false,"start_time":"2024-04-16T07:14:51.250890","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader\n","train_dataloader=DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=False)\n","val_dataloader=DataLoader(val_dataset,batch_size=BATCH_SIZE,shuffle=False)"]},{"cell_type":"code","execution_count":20,"metadata":{"papermill":{"duration":0.020642,"end_time":"2024-04-16T07:14:51.333786","exception":false,"start_time":"2024-04-16T07:14:51.313144","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# class MyModel(nn.Module):\n","#     def __init__(self, input_size=MAX_LENGTH*2, hidden_size=MAX_UTTERANCES, num_linear_layers=MAX_UTTERANCES, linear_size=2):\n","#         super(MyModel, self).__init__()\n","        \n","\n","#         self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True, bidirectional=True, num_layers=2)\n","        \n","#         self.linear_layers1 = nn.ModuleList([nn.Linear(hidden_size*2, 128) for _ in range(num_linear_layers)])\n","#         self.relu = nn.ReLU()\n","#         self.linear_layers2 = nn.ModuleList([nn.Linear(128, linear_size) for _ in range(num_linear_layers)])\n","#         # self.softmax_layers = nn.ModuleList([nn.Softmax(dim=1) for _ in range(num_linear_layers)])\n","#         self.sigmoid = nn.Sigmoid()\n","#     def forward(self, x):\n"," \n","#         for name, param in self.named_parameters():\n","#             if torch.isnan(param).any():\n","#                 print(name, \"is nan\")\n","#                 os.exit(0)\n","\n","#         lstm_out, _ = self.lstm(x)\n","\n","#         # print(\"Output shape of lstm = \",lstm_out.shape)\n","\n","#         if(torch.isnan(lstm_out).any()):\n","#             print(\"lstm_out is nan\"*10)\n","#             print(\"NAN \"*10)\n","#             exit(0)\n","            \n","#         softmax_outputs = []\n","#         for i in range(len(self.linear_layers1)):\n","#             linear_output1 = self.linear_layers1[i](lstm_out[:, -1, :])\n","\n","#             relu_output = self.relu(linear_output1)\n","\n","#             linear_output2= self.linear_layers2[i](relu_output)\n","\n","\n","#             # softmax_output = self.softmax_layers[i](linear_output2)\n","#             sigmoid_output = self.sigmoid(linear_output2)\n","#             softmax_outputs.append(sigmoid_output.float())\n","           \n","#         stacked_tensor = torch.stack(softmax_outputs, dim=1)\n","#         return stacked_tensor\n","# #         return stacked_tensor.clone().detach().requires_grad_(True)\n","\n","# model = MyModel()\n","# model.to(device)\n","# modnum=3\n","# optim = torch.optim.SGD(model.parameters(),lr=0.01,weight_decay=0.01)\n","# scheduler = ReduceLROnPlateau(optim,mode='min', patience=3, factor=0.5)\n"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T23:03:49.883222Z","iopub.status.busy":"2024-04-16T23:03:49.882809Z","iopub.status.idle":"2024-04-16T23:03:49.892282Z","shell.execute_reply":"2024-04-16T23:03:49.891301Z","shell.execute_reply.started":"2024-04-16T23:03:49.883194Z"},"papermill":{"duration":0.024472,"end_time":"2024-04-16T07:14:51.371218","exception":false,"start_time":"2024-04-16T07:14:51.346746","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# class MyModel(nn.Module):\n","#     def __init__(self, input_size=MAX_LENGTH*2, hidden_size=MAX_UTTERANCES, num_linear_layers=MAX_UTTERANCES, linear_size=2):\n","#         super(MyModel, self).__init__()\n","        \n","\n","#         self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True, bidirectional=False, num_layers=2)\n","        \n","#         self.linear_layers1 = nn.ModuleList([nn.Linear(hidden_size, 128) for _ in range(num_linear_layers)])\n","#         self.relu = nn.ReLU()\n","#         self.linear_layers2 = nn.ModuleList([nn.Linear(128, linear_size) for _ in range(num_linear_layers)])\n","#         # self.softmax_layers = nn.ModuleList([nn.Softmax(dim=1) for _ in range(num_linear_layers)])\n","#         self.sigmoid = nn.Sigmoid()\n","#     def forward(self, x):\n"," \n","#         for name, param in self.named_parameters():\n","#             if torch.isnan(param).any():\n","#                 print(name, \"is nan\")\n","#                 os.exit(0)\n","\n","#         lstm_out, _ = self.lstm(x)\n","\n","#         # print(\"Output shape of lstm = \",lstm_out.shape)\n","\n","#         if(torch.isnan(lstm_out).any()):\n","#             print(\"lstm_out is nan\"*10)\n","#             print(\"NAN \"*10)\n","#             exit(0)\n","            \n","#         softmax_outputs = []\n","#         for i in range(len(self.linear_layers1)):\n","#             linear_output1 = self.linear_layers1[i](lstm_out[:, -1, :])\n","\n","#             relu_output = self.relu(linear_output1)\n","\n","#             linear_output2= self.linear_layers2[i](relu_output)\n","\n","\n","#             # softmax_output = self.softmax_layers[i](linear_output2)\n","#             sigmoid_output = self.sigmoid(linear_output2)\n","#             softmax_outputs.append(sigmoid_output.float())\n","           \n","#         stacked_tensor = torch.stack(softmax_outputs, dim=1)\n","#         return stacked_tensor\n","# #         return stacked_tensor.clone().detach().requires_grad_(True)\n","\n","# model = MyModel()\n","# model.to(device)\n","# modnum=3\n","# optim = torch.optim.SGD(model.parameters(),lr=0.01,weight_decay=0.01)\n","# scheduler = ReduceLROnPlateau(optim,mode='min', patience=3, factor=0.5)\n"]},{"cell_type":"code","execution_count":22,"id":"1a1d7cbf","metadata":{},"outputs":[],"source":["# import torch\n","# import torch.nn as nn\n","\n","# class MyModel(nn.Module):\n","#     def __init__(self, input_size=MAX_LENGTH*2, lstm_hidden_size=256, transformer_hidden_size=512, num_linear_layers=MAX_UTTERANCES, linear_size=2):\n","#         super(MyModel, self).__init__()\n","        \n","#         self.transformer_layer = nn.TransformerEncoderLayer(d_model=input_size, nhead=8, batch_first=True)\n","#         self.transformer_encoder = nn.TransformerEncoder(self.transformer_layer, num_layers=4)\n","        \n","#         # self.lstm = nn.LSTM(transformer_hidden_size, lstm_hidden_size, batch_first=True, bidirectional=True, num_layers=3)\n","        \n","#         self.linear_layers1 = nn.ModuleList([nn.Linear(lstm_hidden_size*2, 128) for _ in range(num_linear_layers)])\n","#         self.relu = nn.Relu()\n","#         self.linear_layers2 = nn.ModuleList([nn.Linear(128, linear_size) for _ in range(num_linear_layers)])\n","#         self.sigmoid = nn.Softmax(dim=1)\n","    \n","#     def forward(self, x):\n","\n","#         # check if nan, \n","#         # print(torch.isnan(x).any())\n","\n","#         for name, param in self.named_parameters():\n","#             if torch.isnan(param).any():\n","#                 print(name, \"is nan\")\n","#                 os.exit(0)\n","\n","#         transformer_out = self.transformer_encoder(x)\n","\n","#         if(torch.isnan(transformer_out).any()):\n","#             print(\"transformer_out is nan\"*10)\n","#             print(\"NAN \"*10)\n","#             os.exit(0)\n","#             # print(transformer_out)\n","#         # lstm_out, _ = self.lstm(transformer_out)\n","\n","#         # if(torch.isnan(lstm_out).any()):\n","#         #     print(\"lstm_out is nan\"*10)\n","#         #     print(\"NAN \"*10)\n","#         #     exit(0)\n","#         #     # print(lstm_out)\n","\n","#         # out=lstm_out\n","#         out=transformer_out\n","#         # print(\"Output = \",out)\n","#         softmax_outputs = []\n","#         for i in range(len(self.linear_layers1)):\n","#             linear_output1 = self.linear_layers1[i](out[:, -1, :])\n","#             # print(\"linear: \",linear_output1)\n","#             relu_output = self.relu(linear_output1)\n","#             linear_output2 = self.linear_layers2[i](relu_output)\n","#             activation_output = self.relu(linear_output2)\n","#             sigmoid_output = self.sigmoid(activation_output)\n","#             softmax_outputs.append(sigmoid_output.float())\n","           \n","#         stacked_tensor = torch.stack(softmax_outputs, dim=1)\n","#         return stacked_tensor\n","\n","\n","# model = MyModel()\n","# model.to(device)\n","# modnum=4\n","# optim = torch.optim.SGD(model.parameters(),lr=0.01,weight_decay=0.01)\n","# scheduler = ReduceLROnPlateau(optim,mode='min', patience=3, factor=0.5)\n"]},{"cell_type":"code","execution_count":23,"id":"b00a7dd1","metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class MyModel(nn.Module):\n","    def __init__(self, input_size=MAX_LENGTH*2, lstm_hidden_size=256, transformer_hidden_size=512, num_linear_layers=MAX_UTTERANCES, linear_size=2):\n","        super(MyModel, self).__init__()\n","        \n","        self.transformer_layer = nn.TransformerEncoderLayer(d_model=input_size, nhead=8, batch_first=True)\n","        self.transformer_encoder = nn.TransformerEncoder(self.transformer_layer, num_layers=4)\n","        \n","        self.lstm = nn.LSTM(transformer_hidden_size, lstm_hidden_size, batch_first=True, bidirectional=True, num_layers=3)\n","        \n","        self.linear_layers1 = nn.ModuleList([nn.Linear(lstm_hidden_size*2, 128) for _ in range(num_linear_layers)])\n","        self.relu = nn.Tanh()\n","        self.linear_layers2 = nn.ModuleList([nn.Linear(128, linear_size) for _ in range(num_linear_layers)])\n","        self.sigmoid = nn.Sigmoid()\n","    \n","    def forward(self, x):\n","\n","        # check if nan, \n","        # print(torch.isnan(x).any())\n","\n","        for name, param in self.named_parameters():\n","            if torch.isnan(param).any():\n","                print(name, \"is nan\")\n","                os.exit(0)\n","\n","        transformer_out = self.transformer_encoder(x)\n","\n","        if(torch.isnan(transformer_out).any()):\n","            print(\"transformer_out is nan\"*10)\n","            print(\"NAN \"*10)\n","            os.exit(0)\n","            # print(transformer_out)\n","        lstm_out, _ = self.lstm(transformer_out)\n","\n","        if(torch.isnan(lstm_out).any()):\n","            print(\"lstm_out is nan\"*10)\n","            print(\"NAN \"*10)\n","            exit(0)\n","            # print(lstm_out)\n","\n","        # out=transformer_out\n","        out=lstm_out\n","        # print(\"Output = \",out)\n","        softmax_outputs = []\n","        for i in range(len(self.linear_layers1)):\n","            linear_output1 = self.linear_layers1[i](out[:, -1, :])\n","            # print(\"linear: \",linear_output1)\n","            relu_output = self.relu(linear_output1)\n","            linear_output2 = self.linear_layers2[i](relu_output)\n","            activation_output = self.relu(linear_output2)\n","            sigmoid_output = self.sigmoid(activation_output)\n","            softmax_outputs.append(sigmoid_output.float())\n","           \n","        stacked_tensor = torch.stack(softmax_outputs, dim=1)\n","        return stacked_tensor\n","\n","\n","model = MyModel()\n","model.to(device)\n","modnum=4\n","optim = torch.optim.AdamW(model.parameters(),lr=0.001,weight_decay=0.01)\n","scheduler = ReduceLROnPlateau(optim,mode='min', patience=3, factor=0.5)\n"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T23:03:53.477269Z","iopub.status.busy":"2024-04-16T23:03:53.476425Z","iopub.status.idle":"2024-04-16T23:03:53.751840Z","shell.execute_reply":"2024-04-16T23:03:53.750881Z","shell.execute_reply.started":"2024-04-16T23:03:53.477232Z"},"papermill":{"duration":0.32396,"end_time":"2024-04-16T07:14:51.708297","exception":false,"start_time":"2024-04-16T07:14:51.384337","status":"completed"},"tags":[],"trusted":true},"outputs":[{"data":{"text/plain":["MyModel(\n","  (transformer_layer): TransformerEncoderLayer(\n","    (self_attn): MultiheadAttention(\n","      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n","    )\n","    (linear1): Linear(in_features=512, out_features=2048, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (linear2): Linear(in_features=2048, out_features=512, bias=True)\n","    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","    (dropout1): Dropout(p=0.1, inplace=False)\n","    (dropout2): Dropout(p=0.1, inplace=False)\n","  )\n","  (transformer_encoder): TransformerEncoder(\n","    (layers): ModuleList(\n","      (0-3): 4 x TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n","        )\n","        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n","        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout1): Dropout(p=0.1, inplace=False)\n","        (dropout2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","  )\n","  (lstm): LSTM(512, 256, num_layers=3, batch_first=True, bidirectional=True)\n","  (linear_layers1): ModuleList(\n","    (0-23): 24 x Linear(in_features=512, out_features=128, bias=True)\n","  )\n","  (relu): Tanh()\n","  (linear_layers2): ModuleList(\n","    (0-23): 24 x Linear(in_features=128, out_features=2, bias=True)\n","  )\n","  (sigmoid): Sigmoid()\n",")"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T23:05:48.370328Z","iopub.status.busy":"2024-04-16T23:05:48.369951Z","iopub.status.idle":"2024-04-16T23:05:48.375835Z","shell.execute_reply":"2024-04-16T23:05:48.374814Z","shell.execute_reply.started":"2024-04-16T23:05:48.370300Z"},"papermill":{"duration":0.020586,"end_time":"2024-04-16T07:14:51.742597","exception":false,"start_time":"2024-04-16T07:14:51.722011","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import torch.nn as nn\n","\n","criterion = nn.functional.cross_entropy\n","\n","def metrics(y_true, y_pred):\n","    acc=accuracy_score(y_true, y_pred)\n","    f1_macro=f1_score(y_true, y_pred, average='macro')  \n","    f1_scores=f1_score(y_true, y_pred, average=\"weighted\")\n","    return acc, f1_macro, f1_scores\n"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T23:05:50.366591Z","iopub.status.busy":"2024-04-16T23:05:50.365901Z","iopub.status.idle":"2024-04-16T23:05:50.384522Z","shell.execute_reply":"2024-04-16T23:05:50.383609Z","shell.execute_reply.started":"2024-04-16T23:05:50.366558Z"},"papermill":{"duration":0.030149,"end_time":"2024-04-16T07:14:51.787024","exception":false,"start_time":"2024-04-16T07:14:51.756875","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["\n","\n","def train_epoch(model, optimizer,epoch,val_dataloader,train_dataloader,metrics,weights,scheduler):\n","    model.train()\n","    losses = 0\n","    loss= 0\n","    preds = []\n","    actuals = []\n","    for batch in tqdm(train_dataloader, desc=f\"Epoch:{epoch}, train_loss:{loss}\",total=len(train_dataloader), leave=False):\n","\n","        input_ids = batch[0].to(device)\n","        # attention_mask = batch[1].to(device)\n","        labels = batch[1].to(device)\n","\n","        batch_size = input_ids.size(0)\n","        utt_size = input_ids.size(1)\n","        # print(input_ids.shape)\n","        outputs  = model(input_ids.float())\n","        # print(outputs.shape)\n","        outputs=outputs.view(batch_size*utt_size,-1)\n","        labels=labels.view(batch_size*utt_size)\n","        \n","        # print(outputs.shape,labels.shape)\n","        # print(outputs)\n","\n","        loss = criterion(outputs, labels, weight=weights)\n","\n","        loss = loss.to(device)\n","#         print(\"Loss = \",loss.item)\n","        losses+=loss.item()\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        # for name, param in model.named_parameters():\n","        #     if param.grad is not None:\n","        #         print(f'Gradient - {name}: {param.grad.norm()}')\n","    \n","        _, pred = torch.max(outputs, 1)\n","\n","        # Flatten the predictions and targets\n","        predicted_flat = pred.view(-1)\n","        targets_flat = labels.view(-1)\n","\n","        preds.extend(predicted_flat.cpu().numpy())\n","        actuals.extend(targets_flat.cpu().numpy())\n","\n","        del input_ids\n","        # del attention_mask\n","        del labels\n","        del outputs\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # break\n","#     print(\"BATCH FINISHED\")\n","    x = losses /len(train_dataloader)\n","    tqdm.write(f\"Epoch:{epoch}, Avg Train Loss: {x}\")\n","    acc,macro,f1 = metrics(actuals,preds)\n","    tqdm.write(f\"Avg Training Accuracy: {acc}, F1 Macro: {macro}, F1 Scores: {f1}\")\n","    val_loss,acc,macro,f1,_ = evaluate(model,val_dataloader,\"Validation\",metrics,weights)\n","    scheduler.step(val_loss)\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","    return x,val_loss\n","\n","\n","\n","\n","def evaluate(model,val_dataloader,name,metric,weights):\n","\n","    with torch.no_grad():\n","        model.eval()\n","        losses = 0\n","\n","        preds = []\n","        actuals = []\n","        for batch in tqdm(val_dataloader, desc=name,total=len(val_dataloader), leave=False):\n","\n","                input_ids = batch[0].to(device)\n","                # attention_mask = batch[1].to(device)\n","                labels = batch[1].to(device)\n","\n","                batch_size = input_ids.size(0)\n","                utt_size = labels.size(1)\n","\n","                outputs  = model(input_ids.float())\n","\n","                size_diff = labels.size(1) - outputs.size(1)\n","\n","                # paddings=torch.zeros(batch_size,size_diff,2).to(device)\n","\n","\n","                # print(outputs.shape,paddings.shape)\n","                # predicted = torch.cat((outputs,paddings),dim=1)\n","\n","                predicted=outputs.view(batch_size*utt_size,-1)\n","                labels=labels.view(batch_size*utt_size)\n","                \n","                # print(outputs.shape,labels.shape)\n","                # loss = criterion(predicted, labels)\n","                loss = criterion(predicted, labels, weight=weights)\n","\n","\n","                loss = loss.to(device)\n","        #         print(\"Loss = \",loss.item)\n","                losses+=loss.item()\n","    \n","                _, pred = torch.max(predicted, 1)\n","\n","                # Flatten the predictions and targets\n","                predicted_flat = pred.view(-1)\n","                targets_flat = labels.view(-1)\n","\n","                preds.extend(predicted_flat.cpu().numpy())\n","                actuals.extend(targets_flat.cpu().numpy())\n","\n","                del input_ids\n","                # del attention_mask\n","                del labels\n","                del predicted\n","                # del predicted_labels\n","                gc.collect()\n","                torch.cuda.empty_cache()\n","            # break\n","        # print(losses,len(val_dataloader))\n","        x = losses / len(val_dataloader)\n","        tqdm.write(f\"Avg {name} Loss: {x}\")\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        acc,macro,f1 = metric(actuals,preds)\n","        tqdm.write(f\"Avg {name} Accuracy: {acc}, F1 Macro: {macro}, F1 Scores: {f1}\")\n","        return x,acc,macro,f1,preds"]},{"cell_type":"code","execution_count":27,"id":"92f1d068","metadata":{"execution":{"iopub.execute_input":"2024-04-16T23:05:54.026343Z","iopub.status.busy":"2024-04-16T23:05:54.025340Z","iopub.status.idle":"2024-04-16T23:05:54.032296Z","shell.execute_reply":"2024-04-16T23:05:54.030969Z","shell.execute_reply.started":"2024-04-16T23:05:54.026306Z"},"papermill":{"duration":0.020682,"end_time":"2024-04-16T07:14:51.821292","exception":false,"start_time":"2024-04-16T07:14:51.800610","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# optim = torch.optim.AdamW(model.parameters(),lr=1e-1,weight_decay=0.01)\n","# scheduler = None"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T23:05:59.499427Z","iopub.status.busy":"2024-04-16T23:05:59.499073Z"},"papermill":{"duration":1512.626326,"end_time":"2024-04-16T07:40:04.460927","exception":false,"start_time":"2024-04-16T07:14:51.834601","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["a=0.5\n","train_loss=[]\n","eval_loss=[]\n","weights=torch.tensor([a,1-a]).to(device)\n","for i in range(1,EPOCHS+1):\n","    t,e=train_epoch(model,optim,i,val_dataloader,train_dataloader,metrics,weights,scheduler)\n","    train_loss.append(t)\n","    eval_loss.append(e)\n","    if(i%5==0):\n","        torch.save(model.state_dict(),OUTPATH+f\"model_{modnum}_{i}.pth\")\n","    # evaluate(model,val_dataloader,\"Validation\",metrics)"]},{"cell_type":"code","execution_count":29,"metadata":{"papermill":{"duration":0.410999,"end_time":"2024-04-16T07:40:05.325123","exception":false,"start_time":"2024-04-16T07:40:04.914124","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# # plot the training and validation loss\n","# import matplotlib.pyplot as plt\n","# plt.plot(train_loss, label='Training loss')\n","# plt.plot(eval_loss, label='Validation loss')\n","# plt.xlabel(\"Epochs\")\n","# plt.ylabel(\"Loss\")\n","# plt.title(\"Training and Validation Loss vs epoch\")\n","# plt.legend()\n","# plt.show()"]},{"cell_type":"code","execution_count":30,"metadata":{"papermill":{"duration":0.767465,"end_time":"2024-04-16T07:40:06.492005","exception":false,"start_time":"2024-04-16T07:40:05.724540","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# torch.save(model, f\"{OUTPATH}modelM{modnum}.pth\")\n","# torch.save(tokenizer, f\"{OUTPATH}tokenizerM{modnum}.pth\")"]},{"cell_type":"code","execution_count":31,"metadata":{"papermill":{"duration":1.324971,"end_time":"2024-04-16T07:40:08.217842","exception":true,"start_time":"2024-04-16T07:40:06.892871","status":"failed"},"tags":[],"trusted":true},"outputs":[],"source":["# load model\n","loaded_model = torch.load(f\"{OUTPATH}modelM{modnum}.pth\")\n","loaded_tokenizer = torch.load(f\"{OUTPATH}tokenizerM{modnum}.pth\")\n","# weights=torch.tensor([0.1,0.9]).to(device)\n","\n"]},{"cell_type":"code","execution_count":32,"id":"a569c0a4","metadata":{},"outputs":[{"data":{"text/plain":["MyModel(\n","  (transformer_layer): TransformerEncoderLayer(\n","    (self_attn): MultiheadAttention(\n","      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n","    )\n","    (linear1): Linear(in_features=512, out_features=2048, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (linear2): Linear(in_features=2048, out_features=512, bias=True)\n","    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","    (dropout1): Dropout(p=0.1, inplace=False)\n","    (dropout2): Dropout(p=0.1, inplace=False)\n","  )\n","  (transformer_encoder): TransformerEncoder(\n","    (layers): ModuleList(\n","      (0-3): 4 x TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n","        )\n","        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n","        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout1): Dropout(p=0.1, inplace=False)\n","        (dropout2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","  )\n","  (lstm): LSTM(512, 256, num_layers=3, batch_first=True, bidirectional=True)\n","  (linear_layers1): ModuleList(\n","    (0-23): 24 x Linear(in_features=512, out_features=128, bias=True)\n","  )\n","  (relu): Tanh()\n","  (linear_layers2): ModuleList(\n","    (0-23): 24 x Linear(in_features=128, out_features=2, bias=True)\n","  )\n","  (sigmoid): Softmax(dim=1)\n",")"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["loaded_model"]},{"cell_type":"code","execution_count":33,"id":"4d9156aa","metadata":{},"outputs":[],"source":["\n","# test\n","x_test, y_test = get_train(load_data(PATH+\"val_file.json\"))\n","\n"]},{"cell_type":"code","execution_count":34,"id":"503ca6b6","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Test:   0%|          | 0/2 [00:00<?, ?it/s]c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:685: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n","  return torch._transformer_encoder_layer_fwd(\n","                                                   \r"]},{"name":"stdout","output_type":"stream","text":["Avg Test Loss: 0.692286878824234\n","Avg Test Accuracy: 0.18638790035587188, F1 Macro: 0.17653674674773856, F1 Scores: 0.1303647502842283\n"]}],"source":["test_dataset = Dataset(x_test,loaded_tokenizer,y_test)\n","test_dataloader=DataLoader(test_dataset,batch_size=BATCH_SIZE,shuffle=False)\n","loss,acc,macro,f1,preds=evaluate(loaded_model,test_dataloader,\"Test\",metrics,weights)\n"]},{"cell_type":"code","execution_count":35,"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"source":["y_test_list = np.array(y_test).flatten()\n","preds=np.array(preds).flatten()"]},{"cell_type":"code","execution_count":36,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["({-100: 12939, 0: 6186, 1: 1107}, {0: 8487, 1: 11745})"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["dic1={}\n","dic2={}\n","for i in range(len(y_test_list)):\n","    if y_test_list[i] in dic1:\n","        dic1[y_test_list[i]]+=1\n","    else:\n","        dic1[y_test_list[i]]=1\n","    if preds[i] in dic2:\n","        dic2[preds[i]]+=1\n","    else:\n","        dic2[preds[i]]=1\n","\n","dic1,dic2"]},{"cell_type":"code","execution_count":37,"id":"1566d609","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.91      0.48      0.63      6186\n","           1       0.20      0.73      0.31      1107\n","\n","    accuracy                           0.52      7293\n","   macro avg       0.55      0.60      0.47      7293\n","weighted avg       0.80      0.52      0.58      7293\n","\n","F1 score for label 0: 0.6272226926333616\n","F1 score for label 1: 0.31451926819774234\n"]},{"data":{"text/plain":["({0: 6186, 1: 1107}, {1: 4031, 0: 3262})"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["p=[]\n","a=[]\n","for i in range(len(y_test_list)):\n","    if(y_test_list[i]!=-100):\n","        # print(y_test_list[i],preds[i])\n","        p.append(preds[i])\n","        a.append(y_test_list[i])\n","\n","print(classification_report(a,p))\n","f1_s=f1_score(a,p,average=None)\n","\n","for label, f1 in enumerate(f1_s):\n","    print(f\"F1 score for label {label}: {f1}\")\n","\n","dic1={}\n","dic2={}\n","for i in range(len(p)):\n","    if p[i] in dic1:\n","        dic1[p[i]]+=1\n","    else:\n","        dic1[p[i]]=1\n","    if a[i] in dic2:\n","        dic2[a[i]]+=1\n","    else:\n","        dic2[a[i]]=1\n","\n","dic2,dic1\n"]},{"cell_type":"code","execution_count":38,"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","        -100       0.00      0.00      0.00     12939\n","           0       0.35      0.48      0.40      6186\n","           1       0.07      0.73      0.13      1107\n","\n","    accuracy                           0.19     20232\n","   macro avg       0.14      0.40      0.18     20232\n","weighted avg       0.11      0.19      0.13     20232\n","\n","F1 score for label 0: 0.0\n","F1 score for label 1: 0.40387105568050163\n","F1 score for label 2: 0.125739184562714\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["print(classification_report(y_test_list, preds))\n","f1_scores = f1_score(y_test_list,preds, average=None)\n","\n","# Print F1 score for each label\n","for label, f1 in enumerate(f1_scores):\n","    print(f\"F1 score for label {label}: {f1}\")"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4784361,"sourceId":8101413,"sourceType":"datasetVersion"}],"dockerImageVersionId":30684,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"papermill":{"default_parameters":{},"duration":1567.053425,"end_time":"2024-04-16T07:40:12.127159","environment_variables":{},"exception":true,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-04-16T07:14:05.073734","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"046587d17a434f438dcad8db6f54169b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a15932acd0f84790af33b57e55748d37","placeholder":"​","style":"IPY_MODEL_16015fe6e1fd4fd89baa6531bab1367a","value":"vocab.json: 100%"}},"0aabf492a42e434696d2c05db0f4cd40":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_046587d17a434f438dcad8db6f54169b","IPY_MODEL_2fef804d90404cdc8dede0e6fa1acab8","IPY_MODEL_82e74788687542d59a6ef9a1493bed48"],"layout":"IPY_MODEL_fb476a4d32a14781a4cf041dcbf0644a"}},"0aba67b7d11e4333a1c10a8858835ec5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"10ce9a5720564c0a9b32bc9103c9abfb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"118e52f501724c008e11fcbe00eb362c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16015fe6e1fd4fd89baa6531bab1367a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1bb6556e09bf4fefae031e748ec5bbce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e82c273949c54cd2948880aa7919c1a9","IPY_MODEL_875dd1a1f2d64c58b2807225a7108896","IPY_MODEL_d40d8d0c923a48f4b8353bdd2a30715b"],"layout":"IPY_MODEL_202ec4ed95e94abc99bc50a6440c979b"}},"202ec4ed95e94abc99bc50a6440c979b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"247e6731303341e58ee7e724d2ed48b6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"299928a650614616a7b99d2706a2cb97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c538b530ac24fc394984420af914ef1","placeholder":"​","style":"IPY_MODEL_6bc74c78dc7846f39317049aa671ebd8","value":"tokenizer_config.json: 100%"}},"2fef804d90404cdc8dede0e6fa1acab8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_db40d93abf4042fe9701e3d85c749b12","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c7f3e4a04978459ea287f0c958e1f53a","value":898823}},"34124e142bf9475797f6863f6c7acb22":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a58e2f0550d45e0975761053a2e6096":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c538b530ac24fc394984420af914ef1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cbb4987fcc74d8899587cc0936459c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3da4431bac5c4b88ab9d9d1a780031d2","IPY_MODEL_7a1dcf209bdd42e3b65cd1439d9dfaeb","IPY_MODEL_d2adb55f3b6749be84ad2ad66f04d9f4"],"layout":"IPY_MODEL_7109fd5f04e44d5487cdaeff20d25ad9"}},"3da4431bac5c4b88ab9d9d1a780031d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aaa6b639cc114ae586767136a2186614","placeholder":"​","style":"IPY_MODEL_d39bd8522bd24127bea57b8714df46d2","value":"tokenizer.json: 100%"}},"4189cbe2da144ae6b6aed847c27864dd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44464de37c3f4523a2080d6003b06cbd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7003a2817d074e16ab6a3299242bb906","placeholder":"​","style":"IPY_MODEL_cd435ba6c4ad43e4ad4116c843539f3b","value":" 499M/499M [00:05&lt;00:00, 86.9MB/s]"}},"44aaa574747b49a08bebc113f687c55c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a58e2f0550d45e0975761053a2e6096","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8e681752fe3844df8349d541efe6cb6b","value":25}},"52e7095276c54cb0a0c20752397c5694":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55a4f05f69a74ada83ddc9f24d088a9f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"573657e634894eb5a5421467877693d7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61a08a02ee374f30a174bd66fdb97d93":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4189cbe2da144ae6b6aed847c27864dd","placeholder":"​","style":"IPY_MODEL_c1254202a6fc4a1b8e2b92fdd0334037","value":" 481/481 [00:00&lt;00:00, 38.6kB/s]"}},"672cedc8f2444dc3a7ccfe4736f550dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c37ae072e4de4402861f452060dd351e","placeholder":"​","style":"IPY_MODEL_f09f8fd8f05241c2a8b92643ace58057","value":"model.safetensors: 100%"}},"6bc74c78dc7846f39317049aa671ebd8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7003a2817d074e16ab6a3299242bb906":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7109fd5f04e44d5487cdaeff20d25ad9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a1dcf209bdd42e3b65cd1439d9dfaeb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_52e7095276c54cb0a0c20752397c5694","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_83d00f00f66e49a081288d0eb6541061","value":1355863}},"7d2afc35e09f452494946ce967c0bc6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_672cedc8f2444dc3a7ccfe4736f550dd","IPY_MODEL_bfb27f328a624f679ca2099a1453e50b","IPY_MODEL_44464de37c3f4523a2080d6003b06cbd"],"layout":"IPY_MODEL_10ce9a5720564c0a9b32bc9103c9abfb"}},"7e89aa4a09a44ef18acd98153c55932f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82e74788687542d59a6ef9a1493bed48":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_118e52f501724c008e11fcbe00eb362c","placeholder":"​","style":"IPY_MODEL_d7b0bae7eaef41a3a7f951aab7da25f0","value":" 899k/899k [00:00&lt;00:00, 18.2MB/s]"}},"83d00f00f66e49a081288d0eb6541061":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8402066d6bbf49a090c451014c7163e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_299928a650614616a7b99d2706a2cb97","IPY_MODEL_44aaa574747b49a08bebc113f687c55c","IPY_MODEL_9301ed97681f4da6ac21d52e5dcb4e52"],"layout":"IPY_MODEL_9f2946f4145149249c164d6dad7c6b02"}},"870654c96a164000bbf929a407516bf8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"875dd1a1f2d64c58b2807225a7108896":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4941febec5c41289c6445748c8c4fc6","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0aba67b7d11e4333a1c10a8858835ec5","value":456318}},"87ffa0cf262e44c28ea244df7f6495df":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e681752fe3844df8349d541efe6cb6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9301ed97681f4da6ac21d52e5dcb4e52":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9b69541a9a3412599b3f6d89dd2fe04","placeholder":"​","style":"IPY_MODEL_c97f5845bde74cccbb09231b8bfccd9b","value":" 25.0/25.0 [00:00&lt;00:00, 2.01kB/s]"}},"980e272f72ee41a39da1670509eb37bd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9977eea6a5cc4b2eb597b368367eed3e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c232973e78b497e851383de675a35ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9977eea6a5cc4b2eb597b368367eed3e","placeholder":"​","style":"IPY_MODEL_870654c96a164000bbf929a407516bf8","value":"config.json: 100%"}},"9f2946f4145149249c164d6dad7c6b02":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a15932acd0f84790af33b57e55748d37":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aaa6b639cc114ae586767136a2186614":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4941febec5c41289c6445748c8c4fc6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfb27f328a624f679ca2099a1453e50b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_55a4f05f69a74ada83ddc9f24d088a9f","max":498818054,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f732f41318c24b40b27b1f1c002dfccf","value":498818054}},"c1254202a6fc4a1b8e2b92fdd0334037":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c37ae072e4de4402861f452060dd351e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7f3e4a04978459ea287f0c958e1f53a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c8d583c3ef83420a935d00a7035cf89b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c97f5845bde74cccbb09231b8bfccd9b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9b69541a9a3412599b3f6d89dd2fe04":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd435ba6c4ad43e4ad4116c843539f3b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2adb55f3b6749be84ad2ad66f04d9f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa36afdef22648a38d0fb2343185a8ca","placeholder":"​","style":"IPY_MODEL_7e89aa4a09a44ef18acd98153c55932f","value":" 1.36M/1.36M [00:00&lt;00:00, 4.19MB/s]"}},"d3871c50f65e4c8193fb49fcc7fa2d01":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d39bd8522bd24127bea57b8714df46d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d40d8d0c923a48f4b8353bdd2a30715b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3871c50f65e4c8193fb49fcc7fa2d01","placeholder":"​","style":"IPY_MODEL_34124e142bf9475797f6863f6c7acb22","value":" 456k/456k [00:00&lt;00:00, 3.16MB/s]"}},"d7b0bae7eaef41a3a7f951aab7da25f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db40d93abf4042fe9701e3d85c749b12":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e82c273949c54cd2948880aa7919c1a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_247e6731303341e58ee7e724d2ed48b6","placeholder":"​","style":"IPY_MODEL_87ffa0cf262e44c28ea244df7f6495df","value":"merges.txt: 100%"}},"e947dd7ac7a9464cb9e659e5aa918709":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9c232973e78b497e851383de675a35ce","IPY_MODEL_fc78762de6254fb982dd69880af289c2","IPY_MODEL_61a08a02ee374f30a174bd66fdb97d93"],"layout":"IPY_MODEL_c8d583c3ef83420a935d00a7035cf89b"}},"f09f8fd8f05241c2a8b92643ace58057":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f732f41318c24b40b27b1f1c002dfccf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fa36afdef22648a38d0fb2343185a8ca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb476a4d32a14781a4cf041dcbf0644a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc78762de6254fb982dd69880af289c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_573657e634894eb5a5421467877693d7","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_980e272f72ee41a39da1670509eb37bd","value":481}}},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":5}
