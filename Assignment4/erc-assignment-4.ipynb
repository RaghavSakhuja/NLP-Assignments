{"cells":[{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T15:52:22.535472Z","iopub.status.busy":"2024-04-12T15:52:22.535044Z","iopub.status.idle":"2024-04-12T15:52:46.882205Z","shell.execute_reply":"2024-04-12T15:52:46.880782Z","shell.execute_reply.started":"2024-04-12T15:52:22.535439Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x201de297890>"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","from datasets import load_dataset\n","from transformers import (\n","    RobertaTokenizerFast,\n","    RobertaForSequenceClassification,\n","    TrainingArguments,\n","    Trainer,\n","    AutoConfig,\n",")\n","# from sklearnex import patch_sklearn\n","# patch_sklearn()\n","\n","import json\n","import pandas as pd\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.pipeline import Pipeline\n","from sklearn.svm import SVC\n","from sklearn.linear_model import LogisticRegression\n","import pickle\n","import numpy as np\n","from sklearn.metrics import balanced_accuracy_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import classification_report\n","\n","import torch\n","from torch import nn\n","from transformers import AutoTokenizer\n","from sklearn.model_selection import train_test_split\n","from transformers import BertForSequenceClassification\n","import transformers\n","from torch.utils.data import Dataset, DataLoader\n","#from transformers import *\n","import torch.optim as optim\n","# from tqdm import tqdm\n","from tqdm.notebook import tqdm\n","import pandas as pd\n","import numpy as np\n","import scipy\n","from scipy.stats import pearsonr\n","from torch.optim.lr_scheduler import StepLR\n","\n","torch.manual_seed(0)\n","\n","\n"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T15:52:46.884899Z","iopub.status.busy":"2024-04-12T15:52:46.884194Z","iopub.status.idle":"2024-04-12T15:52:46.893000Z","shell.execute_reply":"2024-04-12T15:52:46.891712Z","shell.execute_reply.started":"2024-04-12T15:52:46.884864Z"},"trusted":true},"outputs":[],"source":["PATH='train_file.json'\n","EOS='</s>'\n","SEP='[SEP]'\n","SOS='<s>'\n","BATCH_SIZE=16\n","NUM_EPOCHS=10\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model_id = \"roberta-large\"\n","label_encoder = LabelEncoder()\n","tokenizer=AutoTokenizer.from_pretrained('bert-base-uncased')"]},{"cell_type":"markdown","metadata":{},"source":["# dataset"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T15:52:46.895168Z","iopub.status.busy":"2024-04-12T15:52:46.894679Z","iopub.status.idle":"2024-04-12T15:52:47.386408Z","shell.execute_reply":"2024-04-12T15:52:47.385078Z","shell.execute_reply.started":"2024-04-12T15:52:46.895136Z"},"trusted":true},"outputs":[],"source":["\n","\n","# read json\n","with open(PATH) as f:\n","    data = json.load(f)\n","    # to pandas\n","    df = pd.DataFrame(data)\n"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T15:52:47.389930Z","iopub.status.busy":"2024-04-12T15:52:47.389145Z","iopub.status.idle":"2024-04-12T15:52:47.412604Z","shell.execute_reply":"2024-04-12T15:52:47.411304Z","shell.execute_reply.started":"2024-04-12T15:52:47.389895Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>episode</th>\n","      <th>speakers</th>\n","      <th>emotions</th>\n","      <th>utterances</th>\n","      <th>triggers</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>utterance_3492</td>\n","      <td>[Phoebe, Eric, Phoebe, Eric, Phoebe]</td>\n","      <td>[surprise, fear, surprise, sadness, disgust]</td>\n","      <td>[You-youyou had sex with Ursula?!, Uh, a litt...</td>\n","      <td>[1.0, 1.0, 0.0, 0.0, 0.0]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>utterance_3952</td>\n","      <td>[Monica, Monica, Phoebe, Joey, Joey, Joey, Rac...</td>\n","      <td>[disgust, disgust, anger, sadness, surprise, a...</td>\n","      <td>[Dad, please don't pick your teeth out here!, ...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>utterance_3198</td>\n","      <td>[Older Scientist, Ross, Ross, Joey, Ross, Ross...</td>\n","      <td>[neutral, neutral, neutral, neutral, neutral, ...</td>\n","      <td>[Dr. Geller, there's a seat over here., Thank ...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>utterance_2834</td>\n","      <td>[Monica, Monica, Monica]</td>\n","      <td>[neutral, surprise, neutral]</td>\n","      <td>[So, how'd the lasagne go over?, Really?!, Good.]</td>\n","      <td>[0.0, 0.0, 1.0]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>utterance_453</td>\n","      <td>[Kate, The Director, Kate]</td>\n","      <td>[joy, sadness, sadness]</td>\n","      <td>[Become a drama critic!, I am hurt!  A plague ...</td>\n","      <td>[0.0, 0.0, 1.0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          episode                                           speakers  \\\n","0  utterance_3492               [Phoebe, Eric, Phoebe, Eric, Phoebe]   \n","1  utterance_3952  [Monica, Monica, Phoebe, Joey, Joey, Joey, Rac...   \n","2  utterance_3198  [Older Scientist, Ross, Ross, Joey, Ross, Ross...   \n","3  utterance_2834                           [Monica, Monica, Monica]   \n","4   utterance_453                         [Kate, The Director, Kate]   \n","\n","                                            emotions  \\\n","0       [surprise, fear, surprise, sadness, disgust]   \n","1  [disgust, disgust, anger, sadness, surprise, a...   \n","2  [neutral, neutral, neutral, neutral, neutral, ...   \n","3                       [neutral, surprise, neutral]   \n","4                            [joy, sadness, sadness]   \n","\n","                                          utterances  \\\n","0  [You-you\n","you had sex with Ursula?!, Uh, a litt...   \n","1  [Dad, please don't pick your teeth out here!, ...   \n","2  [Dr. Geller, there's a seat over here., Thank ...   \n","3  [So, how'd the lasagne go over?, Really?!, Good.]   \n","4  [Become a drama critic!, I am hurt!  A plague ...   \n","\n","                                            triggers  \n","0                          [1.0, 1.0, 0.0, 0.0, 0.0]  \n","1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n","2                [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]  \n","3                                    [0.0, 0.0, 1.0]  \n","4                                    [0.0, 0.0, 1.0]  "]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T16:39:58.888932Z","iopub.status.busy":"2024-04-12T16:39:58.888425Z","iopub.status.idle":"2024-04-12T16:39:59.615273Z","shell.execute_reply":"2024-04-12T16:39:59.613927Z","shell.execute_reply.started":"2024-04-12T16:39:58.888895Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<s> Phoebe:No. [SEP] Phoebe:No! [SEP] \n","episode          utterance_915\n","speakers      [Phoebe, Phoebe]\n","emotions      [neutral, anger]\n","utterances          [No., No!]\n","triggers            [0.0, 0.0]\n","Name: 968, dtype: object\n","<s> Phoebe:No. [SEP] Phoebe:No! [SEP] \n","episode          utterance_915\n","speakers      [Phoebe, Phoebe]\n","emotions      [neutral, anger]\n","utterances          [No., No!]\n","triggers            [0.0, 0.0]\n","Name: 3984, dtype: object\n"]}],"source":["sentence_len = []\n","text=[]\n","\n","\n","for i in range(len(df)):\n","    uterances=df.iloc[i]['utterances']\n","    speaker=df.iloc[i]['speakers']\n","    length=0\n","    sentence=SOS+' '\n","    for (speaker,uterance) in zip(speaker,uterances):\n","        sentence+=speaker+':'+uterance+' '+SEP+' '\n","\n","        length+=len(uterance.split())\n","    if(length==2):\n","        print(sentence)\n","        print(df.iloc[i])\n","    sentence_len.append(length)\n","    text.append(sentence+EOS)\n","    # print(length)\n","    # break"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T15:52:48.145309Z","iopub.status.busy":"2024-04-12T15:52:48.144733Z","iopub.status.idle":"2024-04-12T15:52:49.231325Z","shell.execute_reply":"2024-04-12T15:52:49.229607Z","shell.execute_reply.started":"2024-04-12T15:52:48.145260Z"},"trusted":true},"outputs":[],"source":["# config =AutoConfig.from_pretrained(model_id)\n","# config.update({\"id2label\": label_to_id})\n","# tokenizer = RobertaTokenizerFast.from_pretrained(model_id)\n","# model = RobertaForSequenceClassification.from_pretrained(model_id,config=config)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T16:40:02.606952Z","iopub.status.busy":"2024-04-12T16:40:02.606493Z","iopub.status.idle":"2024-04-12T16:40:02.624604Z","shell.execute_reply":"2024-04-12T16:40:02.623367Z","shell.execute_reply.started":"2024-04-12T16:40:02.606909Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["6740 4179\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>&lt;s&gt; Phoebe:You-youyou had sex with Ursula?! [...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>&lt;s&gt; Monica:Dad, please don't pick your teeth o...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>&lt;s&gt; Older Scientist:Dr. Geller, there's a seat...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>&lt;s&gt; Monica:So, how'd the lasagne go over? [SEP...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>&lt;s&gt; Kate:Become a drama critic! [SEP] The Dire...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text\n","0  <s> Phoebe:You-you\n","you had sex with Ursula?! [...\n","1  <s> Monica:Dad, please don't pick your teeth o...\n","2  <s> Older Scientist:Dr. Geller, there's a seat...\n","3  <s> Monica:So, how'd the lasagne go over? [SEP...\n","4  <s> Kate:Become a drama critic! [SEP] The Dire..."]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["text_df=pd.DataFrame(text,columns=['text'])\n","print(len(text),len(set(text)))\n","text_df.head()"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T16:40:04.705381Z","iopub.status.busy":"2024-04-12T16:40:04.704102Z","iopub.status.idle":"2024-04-12T16:40:04.710930Z","shell.execute_reply":"2024-04-12T16:40:04.710094Z","shell.execute_reply.started":"2024-04-12T16:40:04.705342Z"},"trusted":true},"outputs":[],"source":["\n","\n","label_encoding ={\n","    'neutral':0,\n","    'surprise':1,\n","    'sadness':2,\n","    'anger':3,\n","    'fear':4,\n","    'disgust':5,\n","    'joy':6\n","}\n","\n"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T16:40:06.075472Z","iopub.status.busy":"2024-04-12T16:40:06.074996Z","iopub.status.idle":"2024-04-12T16:40:06.106887Z","shell.execute_reply":"2024-04-12T16:40:06.105419Z","shell.execute_reply.started":"2024-04-12T16:40:06.075438Z"},"trusted":true},"outputs":[],"source":["\n","\n","y_train=[]\n","for i in df[\"emotions\"]:\n","    lst=[]\n","    for j in i:\n","        lst.append(label_encoding[j])\n","    \n","    lst.extend([128]*(7-len(lst)))\n","    y_train.append(lst)\n","\n","x_train=text_df['text']\n"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, data, tokenizer):\n","        self.data=data\n","        self.tokenizer = tokenizer\n","        \n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        x = self.data.iloc[idx, 0]\n","        y = self.data.iloc[idx, 1]\n","        encoded_x = self.tokenizer(x,\n","                                      add_special_tokens=True, \n","                                      padding='max_length', \n","                                      truncation=True, \n","                                      return_tensors='pt')\n","        input_ids = encoded_x['input_ids'].squeeze(0)\n","        attention_mask = encoded_x['attention_mask'].squeeze(0)\n","        return input_ids,attention_mask,torch.tensor(y)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T16:40:18.946224Z","iopub.status.busy":"2024-04-12T16:40:18.945793Z","iopub.status.idle":"2024-04-12T16:40:18.953572Z","shell.execute_reply":"2024-04-12T16:40:18.952447Z","shell.execute_reply.started":"2024-04-12T16:40:18.946190Z"},"trusted":true},"outputs":[],"source":["train_dataframe=pd.DataFrame({'text':x_train,'label':y_train})\n","train_data=CustomDataset(train_dataframe,tokenizer)\n","train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n","# val_dataframe=pd.DataFrame({'text':x_val,'label':y_val})"]},{"cell_type":"markdown","metadata":{},"source":["# model"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T16:42:19.295792Z","iopub.status.busy":"2024-04-12T16:42:19.295371Z","iopub.status.idle":"2024-04-12T16:42:19.390622Z","shell.execute_reply":"2024-04-12T16:42:19.389052Z","shell.execute_reply.started":"2024-04-12T16:42:19.295761Z"},"trusted":true},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T16:32:25.552269Z","iopub.status.busy":"2024-04-12T16:32:25.551469Z","iopub.status.idle":"2024-04-12T16:32:25.784922Z","shell.execute_reply":"2024-04-12T16:32:25.783724Z","shell.execute_reply.started":"2024-04-12T16:32:25.552232Z"},"trusted":true},"outputs":[],"source":["def plotgraph(train_losses,val_losses):\n","    x=[i+1 for i in range(NUM_EPOCHS)]\n","    plt.plot(train_losses, label='Training Loss')\n","    plt.plot(val_losses, label='Validation Loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.title('Training and Validation Loss per Epoch')\n","    plt.legend()\n","    plt.savefig('loss_graph.png')\n","    plt.show()"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T16:31:01.861348Z","iopub.status.busy":"2024-04-12T16:31:01.860893Z","iopub.status.idle":"2024-04-12T16:31:01.951663Z","shell.execute_reply":"2024-04-12T16:31:01.949508Z","shell.execute_reply.started":"2024-04-12T16:31:01.861315Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["model.safetensors: 100%|██████████| 440M/440M [00:20<00:00, 21.7MB/s] \n","c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\acer\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n","To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n","  warnings.warn(message)\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model=BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=3)\n","# model.classifier = nn.Sequential(\n","#     nn.Linear(model.config.hidden_size, 1),\n","#     nn.Sigmoid()  # Output float between 0 and 1\n","# )\n","model.to(DEVICE)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n","# optimizer=torch.optim.SGD(model.parameters(),lr=0.0005,weight_decay=0.001)\n","loss_fn=nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["import gc\n","import sys\n","gc.collect()\n","torch.cuda.empty_cache()\n","\n","train_losses=[]\n","val_losses=[]"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":4}
