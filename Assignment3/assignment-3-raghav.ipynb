{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"name":"stdout","output_type":"stream","text":["Using GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n"]}],"source":["import os\n","import csv\n","import math\n","import torch\n","import logging\n","import pandas as pd\n","from datetime import datetime\n","from torch.utils.data import DataLoader, Dataset\n","from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n","from sentence_transformers import SentenceTransformer, LoggingHandler, losses, util, InputExample\n","\n","from sentence_transformers import SentenceTransformer,util\n","import torch\n","import scipy\n","from scipy.stats import pearsonr\n","\n","device=\"\"\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    logging.info(f'Using GPU: {torch.cuda.get_device_name()}')\n","    print(f'Using GPU: {torch.cuda.get_device_name()}')\n","else:\n","    device = torch.device(\"cpu\")\n","    logging.info('Using CPU')\n","    print('Using CPU')"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["PATH=\"data/\""]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["\n","\n","class TSDataset(Dataset):\n","    def __init__(self, file_path):\n","        data = []\n","        with open(file_path, encoding=\"utf8\") as f:\n","            reader = csv.DictReader(f, delimiter=\"\\t\")\n","            for row in reader:\n","                data.append(InputExample(texts=[row[\"sentence1\"], row[\"sentence2\"]], label=(float(row[\"score\"]))/5))\n","\n","        self.samples = data\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        sample = self.samples[idx]\n","        return sample\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["model_name = \"all-mpnet-base-v2\"\n","train_batch_size = 32\n","num_epochs = 4"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["logging.basicConfig(\n","    format=\"%(asctime)s - %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\", level=logging.INFO, handlers=[LoggingHandler()]\n",")"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["model_save_path = (\n","    \"output/training-\" + model_name \n",")\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["modules.json: 100%|██████████| 349/349 [00:00<?, ?B/s] \n","c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\acer\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n","To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n","  warnings.warn(message)\n","config_sentence_transformers.json: 100%|██████████| 116/116 [00:00<?, ?B/s] \n","README.md: 100%|██████████| 10.7k/10.7k [00:00<00:00, 10.7MB/s]\n","sentence_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<?, ?B/s]\n","config.json: 100%|██████████| 612/612 [00:00<00:00, 611kB/s]\n","pytorch_model.bin: 100%|██████████| 90.9M/90.9M [00:04<00:00, 20.2MB/s]\n","tokenizer_config.json: 100%|██████████| 350/350 [00:00<?, ?B/s] \n","vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 552kB/s]\n","tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 745kB/s]\n","special_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 112kB/s]\n","1_Pooling/config.json: 100%|██████████| 190/190 [00:00<?, ?B/s] \n"]}],"source":["model = SentenceTransformer(model_name)\n","model.to(device)\n","logging.info(\"Read train dataset\")"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["train_dataset = TSDataset(f\"{PATH}train.csv\")\n","train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n","train_loss = losses.CosineSimilarityLoss(model=model)\n"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["logging.info(\"Read dev dataset\")\n","dev_dataset = TSDataset(f\"{PATH}dev.csv\")\n","\n","# dev_input_examples = [InputExample(texts=[sentence1, sentence2], label=score) for sentence1, sentence2, score in dev_dataset]\n","\n","# evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_input_examples, name=\"dev\")\n","# evaluator = EmbeddingSimilarityEvaluator(dev_dataset)\n","evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_dataset, name=\"dev\")\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)  # 10% of train data for warm-up\n","logging.info(\"Warmup-steps: {}\".format(warmup_steps))"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Iteration: 100%|██████████| 179/179 [00:11<00:00, 15.51it/s]\n","Iteration: 100%|██████████| 179/179 [00:11<00:00, 15.98it/s]\n","Iteration: 100%|██████████| 179/179 [00:11<00:00, 16.02it/s]\n","Iteration: 100%|██████████| 179/179 [00:11<00:00, 15.99it/s]\n","Epoch: 100%|██████████| 4/4 [00:51<00:00, 12.88s/it]\n"]}],"source":["model.fit(\n","    train_objectives=[(train_dataloader, train_loss)],\n","    evaluator=evaluator,\n","    epochs=num_epochs,\n","    evaluation_steps=500,\n","    warmup_steps=warmup_steps,\n","    output_path=model_save_path,\n","    # device=device\n",")"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["# test_dataset = TSDataset(f\"{PATH}test.csv\")"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["untrained_model = SentenceTransformer(model_name)\n","untrained_model.to(device)\n","\n","loaded_model = SentenceTransformer(model_save_path)\n","loaded_model.to(device)\n","\n","models=[untrained_model, loaded_model]"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["validation_data = pd.read_csv(f\"{PATH}dev.csv\",sep=\"\\t\")\n","validation_data\n","validation_data.dropna(inplace=True)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/plain":["((1468,), (1468,))"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["sentence_set_1 = validation_data['sentence1'].to_numpy()\n","sentence_set_2 = validation_data['sentence2'].to_numpy()\n","sentence_set_1.shape,sentence_set_2.shape"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: SentenceTransformer(\n","  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n","  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n","  (2): Normalize()\n",")\n","Pearson's Coeffecient = 0.8631423812646389\n","Model: SentenceTransformer(\n","  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n","  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n","  (2): Normalize()\n",")\n","Pearson's Coeffecient = 0.8935878127304003\n"]}],"source":["for model in models:\n","    print(f\"Model: {model}\")\n","    encode_sentence_set_1 = model.encode(sentence_set_1)\n","    encode_sentence_set_2 = model.encode(sentence_set_2)\n","\n","    cosine_similarities = util.cos_sim(encode_sentence_set_1,encode_sentence_set_2).tolist()\n","\n","    predicted_scores = []\n","    pairwise_pearson=[]\n","    for i in range(len(cosine_similarities)):\n","        cos_score = (cosine_similarities[i][i]+1)/2\n","        pairwise_pearson.append(pearsonr(encode_sentence_set_1[i],encode_sentence_set_2[i])[0])\n","        predicted_scores.append(cos_score*5)\n","        \n","        \n","    data={\n","        'pairwise_pearson':pairwise_pearson,\n","        'predicted_score':predicted_scores,\n","        'sentence1':sentence_set_1,\n","        'sentence2':sentence_set_2\n","    }\n","    final_dataframe = pd.DataFrame(data)\n","    final_dataframe.to_csv(\"task_1_B.csv\")\n","    final_dataframe\n","\n","    score_val = validation_data['score']\n","    score_pred_val = final_dataframe['predicted_score']\n","\n","    print(f\"Pearson's Coeffecient = {pearsonr(score_val,score_pred_val)[0]}\")"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["torch.cuda.empty_cache()"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4645728,"sourceId":7908434,"sourceType":"datasetVersion"}],"dockerImageVersionId":30673,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":4}
