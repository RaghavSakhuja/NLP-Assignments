{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7931344,"sourceType":"datasetVersion","datasetId":4645728}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-26T14:51:32.795592Z","iopub.execute_input":"2024-03-26T14:51:32.796101Z","iopub.status.idle":"2024-03-26T14:51:33.933094Z","shell.execute_reply.started":"2024-03-26T14:51:32.796058Z","shell.execute_reply":"2024-03-26T14:51:33.932041Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/assignment-3/data/Task1/dev.csv\n/kaggle/input/assignment-3/data/Task1/sample_test.csv\n/kaggle/input/assignment-3/data/Task1/sample_demo.csv\n/kaggle/input/assignment-3/data/Task1/train.csv\n/kaggle/input/assignment-3/data/Task2/train_data.json\n/kaggle/input/assignment-3/data/Task2/validation_data.json\n/kaggle/input/assignment-3/data/Task2/test.json\n/kaggle/input/assignment-3/data/A3_task1_data_files/dev.csv\n/kaggle/input/assignment-3/data/A3_task1_data_files/sample_test.csv\n/kaggle/input/assignment-3/data/A3_task1_data_files/sample_demo.csv\n/kaggle/input/assignment-3/data/A3_task1_data_files/train.csv\n/kaggle/input/assignment-3/A3_task1_data_files/dev.csv\n/kaggle/input/assignment-3/A3_task1_data_files/sample_test.csv\n/kaggle/input/assignment-3/A3_task1_data_files/sample_demo.csv\n/kaggle/input/assignment-3/A3_task1_data_files/train.csv\n/kaggle/input/assignment-3/assignment-3/dev.csv\n/kaggle/input/assignment-3/assignment-3/sample_test.csv\n/kaggle/input/assignment-3/assignment-3/sample_demo.csv\n/kaggle/input/assignment-3/assignment-3/train.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -U torchdata\n!pip install -U spacy\n!python -m spacy download en_core_web_lg\n!python -m spacy download de_core_news_lg\n!pip install portalocker","metadata":{"execution":{"iopub.status.busy":"2024-03-26T14:51:33.935131Z","iopub.execute_input":"2024-03-26T14:51:33.935679Z","iopub.status.idle":"2024-03-26T14:53:04.766747Z","shell.execute_reply.started":"2024-03-26T14:51:33.935641Z","shell.execute_reply":"2024-03-26T14:53:04.765566Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchdata in /opt/conda/lib/python3.10/site-packages (0.7.1)\nRequirement already satisfied: urllib3>=1.25 in /opt/conda/lib/python3.10/site-packages (from torchdata) (1.26.18)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchdata) (2.31.0)\nRequirement already satisfied: torch>=2 in /opt/conda/lib/python3.10/site-packages (from torchdata) (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2->torchdata) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=2->torchdata) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2->torchdata) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2->torchdata) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2->torchdata) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=2->torchdata) (2024.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchdata) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchdata) (3.6)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchdata) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2->torchdata) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2->torchdata) (1.3.0)\nRequirement already satisfied: spacy in /opt/conda/lib/python3.10/site-packages (3.7.2)\nCollecting spacy\n  Downloading spacy-3.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (8.2.2)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.9.0)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (6.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (4.66.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.31.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.5.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy) (69.0.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.3.0)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.26.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy) (3.1.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy) (2.1.3)\nDownloading spacy-3.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: spacy\n  Attempting uninstall: spacy\n    Found existing installation: spacy 3.7.2\n    Uninstalling spacy-3.7.2:\n      Successfully uninstalled spacy-3.7.2\nSuccessfully installed spacy-3.7.4\nCollecting en-core-web-sm==3.7.1\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /opt/conda/lib/python3.10/site-packages (from en-core-web-sm==3.7.1) (3.7.4)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.2)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (69.0.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\nCollecting de-core-news-sm==3.7.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from de-core-news-sm==3.7.0) (3.7.4)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.2)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.9.0)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (6.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.66.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.31.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.5.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (69.0.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.0)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.2.2)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.4)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.7)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.1.3)\nInstalling collected packages: de-core-news-sm\nSuccessfully installed de-core-news-sm-3.7.0\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('de_core_news_sm')\nCollecting portalocker\n  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\nDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\nInstalling collected packages: portalocker\nSuccessfully installed portalocker-2.8.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\nimport torch\nfrom torchtext.data.utils import get_tokenizer\nfrom torchtext.vocab import build_vocab_from_iterator\nfrom typing import Iterable, List\nfrom torch import Tensor\nimport torch.nn as nn\nfrom torch.nn import Transformer\nimport math\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nfrom timeit import default_timer as timer\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2024-03-26T14:53:04.768337Z","iopub.execute_input":"2024-03-26T14:53:04.768640Z","iopub.status.idle":"2024-03-26T14:53:08.554491Z","shell.execute_reply.started":"2024-03-26T14:53:04.768613Z","shell.execute_reply":"2024-03-26T14:53:08.553334Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"token_transform = {}\nvocab_transform = {}","metadata":{"execution":{"iopub.status.busy":"2024-03-26T14:53:08.557543Z","iopub.execute_input":"2024-03-26T14:53:08.558660Z","iopub.status.idle":"2024-03-26T14:53:08.562685Z","shell.execute_reply.started":"2024-03-26T14:53:08.558616Z","shell.execute_reply":"2024-03-26T14:53:08.561566Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"SRC_LANGUAGE = 'de'\nTGT_LANGUAGE = 'en'","metadata":{"execution":{"iopub.status.busy":"2024-03-26T14:53:08.563974Z","iopub.execute_input":"2024-03-26T14:53:08.564339Z","iopub.status.idle":"2024-03-26T14:53:08.581372Z","shell.execute_reply.started":"2024-03-26T14:53:08.564307Z","shell.execute_reply":"2024-03-26T14:53:08.580306Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_lg')\ntoken_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_lg')","metadata":{"execution":{"iopub.status.busy":"2024-03-26T14:53:08.582573Z","iopub.execute_input":"2024-03-26T14:53:08.582902Z","iopub.status.idle":"2024-03-26T14:53:13.911653Z","shell.execute_reply.started":"2024-03-26T14:53:08.582877Z","shell.execute_reply":"2024-03-26T14:53:13.910518Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n\n    for data_sample in data_iter:\n        yield token_transform[language](data_sample[language_index[language]])","metadata":{"execution":{"iopub.status.busy":"2024-03-26T14:53:13.913408Z","iopub.execute_input":"2024-03-26T14:53:13.914643Z","iopub.status.idle":"2024-03-26T14:53:13.920430Z","shell.execute_reply.started":"2024-03-26T14:53:13.914602Z","shell.execute_reply":"2024-03-26T14:53:13.919044Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def read_json(file_path):\n    with open(file_path, 'r', encoding='utf-8') as f:\n        data = json.load(f)\n    print(len(data[\"translation\"]))\n    return data[\"translation\"]","metadata":{"execution":{"iopub.status.busy":"2024-03-26T14:53:13.921776Z","iopub.execute_input":"2024-03-26T14:53:13.922198Z","iopub.status.idle":"2024-03-26T14:53:13.941404Z","shell.execute_reply.started":"2024-03-26T14:53:13.922163Z","shell.execute_reply":"2024-03-26T14:53:13.940547Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, json_data):\n        self.data = []\n        for item in json_data:\n            # Assuming each item in JSON is a dictionary with keys 'input' and 'target'\n            input_data = item[SRC_LANGUAGE]\n            target_data = item[TGT_LANGUAGE]\n            self.data.append((input_data, target_data))\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        return self.data[idx]","metadata":{"execution":{"iopub.status.busy":"2024-03-26T14:53:13.942573Z","iopub.execute_input":"2024-03-26T14:53:13.942878Z","iopub.status.idle":"2024-03-26T14:53:13.952598Z","shell.execute_reply.started":"2024-03-26T14:53:13.942854Z","shell.execute_reply":"2024-03-26T14:53:13.951566Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_path=\"/kaggle/input/assignment-3/data/Task2/train_data.json\"\n\nUNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n# Make sure the tokens are in order of their indices to properly insert them in vocab\nspecial_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n\ndef getVocab_train(file_path):\n    for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n        # Create train_iter from JSON file\n        iterator = CustomDataset(read_json(file_path))\n        vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(iterator, ln),\n                                                        min_freq=1,\n                                                        specials=special_symbols,\n                                                        special_first=True)\n    return iterator\n\ntrain_iter = getVocab_train(train_path)\n\nfor ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n    vocab_transform[ln].set_default_index(UNK_IDX)\n        \n","metadata":{"execution":{"iopub.status.busy":"2024-03-26T14:54:51.428428Z","iopub.execute_input":"2024-03-26T14:54:51.428840Z","iopub.status.idle":"2024-03-26T14:55:10.140913Z","shell.execute_reply.started":"2024-03-26T14:54:51.428807Z","shell.execute_reply":"2024-03-26T14:55:10.139830Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"50000\n50000\n","output_type":"stream"}]},{"cell_type":"code","source":"val_path=\"/kaggle/input/assignment-3/data/Task2/validation_data.json\"\nval_iter = CustomDataset(read_json(val_path))\nprint(val_iter)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T14:55:10.143078Z","iopub.execute_input":"2024-03-26T14:55:10.143397Z","iopub.status.idle":"2024-03-26T14:55:10.167428Z","shell.execute_reply.started":"2024-03-26T14:55:10.143371Z","shell.execute_reply":"2024-03-26T14:55:10.166339Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"2169\n<__main__.CustomDataset object at 0x7c3ddd6b6e60>\n","output_type":"stream"}]},{"cell_type":"code","source":"# for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n#     print(f\"Vocabulary for {language}:\")\n#     for token, idx in vocab_transform[language].get_stoi().items():\n#         print(f\"Token: {token}, Index: {idx}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-26T14:55:10.168652Z","iopub.execute_input":"2024-03-26T14:55:10.168976Z","iopub.status.idle":"2024-03-26T14:55:10.173724Z","shell.execute_reply.started":"2024-03-26T14:55:10.168948Z","shell.execute_reply":"2024-03-26T14:55:10.172674Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"print(vocab_transform)\nprint(type(train_iter))","metadata":{"execution":{"iopub.status.busy":"2024-03-26T14:55:10.175422Z","iopub.execute_input":"2024-03-26T14:55:10.175780Z","iopub.status.idle":"2024-03-26T14:55:10.184865Z","shell.execute_reply.started":"2024-03-26T14:55:10.175750Z","shell.execute_reply":"2024-03-26T14:55:10.183776Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"{'de': Vocab(), 'en': Vocab()}\n<class '__main__.CustomDataset'>\n","output_type":"stream"}]},{"cell_type":"code","source":"DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\nclass PositionalEncoding(nn.Module):\n    def __init__(self,\n                 emb_size: int,\n                 dropout: float,\n                 maxlen: int = 5000):\n        super(PositionalEncoding, self).__init__()\n        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n        pos_embedding = torch.zeros((maxlen, emb_size))\n        pos_embedding[:, 0::2] = torch.sin(pos * den)\n        pos_embedding[:, 1::2] = torch.cos(pos * den)\n        pos_embedding = pos_embedding.unsqueeze(-2)\n\n        self.dropout = nn.Dropout(dropout)\n        self.register_buffer('pos_embedding', pos_embedding)\n\n    def forward(self, token_embedding: Tensor):\n        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n\n# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\nclass TokenEmbedding(nn.Module):\n    def __init__(self, vocab_size: int, emb_size):\n        super(TokenEmbedding, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, emb_size)\n        self.emb_size = emb_size\n\n    def forward(self, tokens: Tensor):\n        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n\n# Seq2Seq Network\nclass Seq2SeqTransformer(nn.Module):\n    def __init__(self,\n                 num_encoder_layers: int,\n                 num_decoder_layers: int,\n                 emb_size: int,\n                 nhead: int,\n                 src_vocab_size: int,\n                 tgt_vocab_size: int,\n                 dim_feedforward: int = 512,\n                 dropout: float = 0.1):\n        super(Seq2SeqTransformer, self).__init__()\n        self.transformer = Transformer(d_model=emb_size,\n                                       nhead=nhead,\n                                       num_encoder_layers=num_encoder_layers,\n                                       num_decoder_layers=num_decoder_layers,\n                                       dim_feedforward=dim_feedforward,\n                                       dropout=dropout)\n        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n        self.positional_encoding = PositionalEncoding(\n            emb_size, dropout=dropout)\n\n    def forward(self,\n                src: Tensor,\n                trg: Tensor,\n                src_mask: Tensor,\n                tgt_mask: Tensor,\n                src_padding_mask: Tensor,\n                tgt_padding_mask: Tensor,\n                memory_key_padding_mask: Tensor):\n        src_emb = self.positional_encoding(self.src_tok_emb(src))\n        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n        return self.generator(outs)\n\n    def encode(self, src: Tensor, src_mask: Tensor):\n        return self.transformer.encoder(self.positional_encoding(\n                            self.src_tok_emb(src)), src_mask)\n\n    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n        return self.transformer.decoder(self.positional_encoding(\n                          self.tgt_tok_emb(tgt)), memory,\n                          tgt_mask)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T14:55:10.187975Z","iopub.execute_input":"2024-03-26T14:55:10.188356Z","iopub.status.idle":"2024-03-26T14:55:10.209104Z","shell.execute_reply.started":"2024-03-26T14:55:10.188329Z","shell.execute_reply":"2024-03-26T14:55:10.208042Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def generate_square_subsequent_mask(sz):\n    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n    return mask\n\n\ndef create_mask(src, tgt):\n    src_seq_len = src.shape[0]\n    tgt_seq_len = tgt.shape[0]\n\n    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n\n    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask","metadata":{"execution":{"iopub.status.busy":"2024-03-26T14:55:10.210172Z","iopub.execute_input":"2024-03-26T14:55:10.210453Z","iopub.status.idle":"2024-03-26T14:55:10.226238Z","shell.execute_reply.started":"2024-03-26T14:55:10.210430Z","shell.execute_reply":"2024-03-26T14:55:10.225263Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()\ntorch.manual_seed(0)\n\nSRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\nTGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\nEMB_SIZE = 512\nNHEAD = 8\nFFN_HID_DIM = 512\nBATCH_SIZE = 40\nNUM_ENCODER_LAYERS = 3\nNUM_DECODER_LAYERS = 3\n\ntransformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n\nfor p in transformer.parameters():\n    if p.dim() > 1:\n        nn.init.xavier_uniform_(p)\n\ntransformer = transformer.to(DEVICE)\n\nloss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n\noptimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T14:55:10.227631Z","iopub.execute_input":"2024-03-26T14:55:10.228045Z","iopub.status.idle":"2024-03-26T14:55:14.014147Z","shell.execute_reply.started":"2024-03-26T14:55:10.227985Z","shell.execute_reply":"2024-03-26T14:55:14.013058Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"# helper function to club together sequential operations\ndef sequential_transforms(*transforms):\n    def func(txt_input):\n        for transform in transforms:\n            txt_input = transform(txt_input)\n        return txt_input\n    return func\n\n# function to add BOS/EOS and create tensor for input sequence indices\ndef tensor_transform(token_ids: List[int]):\n    return torch.cat((torch.tensor([BOS_IDX]),\n                      torch.tensor(token_ids),\n                      torch.tensor([EOS_IDX])))\n\n# ``src`` and ``tgt`` language text transforms to convert raw strings into tensors indices\ntext_transform = {}\nfor ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n                                               vocab_transform[ln], #Numericalization\n                                               tensor_transform) # Add BOS/EOS and create tensor\n\n\n# function to collate data samples into batch tensors\ndef collate_fn(batch):\n    src_batch, tgt_batch = [], []\n    for src_sample, tgt_sample in batch:\n        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n\n    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n    return src_batch, tgt_batch","metadata":{"execution":{"iopub.status.busy":"2024-03-26T14:55:14.015383Z","iopub.execute_input":"2024-03-26T14:55:14.015962Z","iopub.status.idle":"2024-03-26T14:55:14.026293Z","shell.execute_reply.started":"2024-03-26T14:55:14.015929Z","shell.execute_reply":"2024-03-26T14:55:14.025066Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"\ndef train_epoch(model, optimizer,epoch):\n    model.train()\n    losses = 0\n    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n    train_dataloader = tqdm(train_dataloader, desc=f\"Epoch:{epoch}\", leave=False)\n\n    for batch in train_dataloader:\n        src = batch[0]\n        tgt = batch[1]\n        src = src.to(DEVICE)\n        tgt = tgt.to(DEVICE)\n\n        tgt_input = tgt[:-1, :]\n\n        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n\n        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n\n        optimizer.zero_grad()\n\n        tgt_out = tgt[1:, :]\n        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n        loss.backward()\n\n        optimizer.step()\n        losses += loss.item()\n        \n    x = losses / len(list(train_dataloader))\n    tqdm.write(f\"Epoch:{epoch}, Avg Train Loss: {x}\")\n    \n    return x\n\n\n\ndef evaluate(model):\n    model.eval()\n    losses = 0\n    val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n\n    for src, tgt in val_dataloader:\n        src = src.to(DEVICE)\n        tgt = tgt.to(DEVICE)\n\n        tgt_input = tgt[:-1, :]\n\n        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n\n        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n\n        tgt_out = tgt[1:, :]\n        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n        losses += loss.item()\n\n    return losses / len(list(val_dataloader))","metadata":{"execution":{"iopub.status.busy":"2024-03-26T14:55:14.027822Z","iopub.execute_input":"2024-03-26T14:55:14.028247Z","iopub.status.idle":"2024-03-26T14:55:14.047631Z","shell.execute_reply.started":"2024-03-26T14:55:14.028211Z","shell.execute_reply":"2024-03-26T14:55:14.046424Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"NUM_EPOCHS = 15\n\nfor epoch in range(1, NUM_EPOCHS+1):\n    start_time = timer()\n    train_loss = train_epoch(transformer, optimizer,epoch)\n    end_time = timer()\n    val_loss = evaluate(transformer)\n    torch.save(model.state_dict(), f\"output/model2A_epoch_{epoch + 1}.pth\")\n    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n\n\n# function to generate output sequence using greedy algorithm\ndef greedy_decode(model, src, src_mask, max_len, start_symbol):\n    src = src.to(DEVICE)\n    src_mask = src_mask.to(DEVICE)\n\n    memory = model.encode(src, src_mask)\n    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n    for i in range(max_len-1):\n        memory = memory.to(DEVICE)\n        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n                    .type(torch.bool)).to(DEVICE)\n        out = model.decode(ys, memory, tgt_mask)\n        out = out.transpose(0, 1)\n        prob = model.generator(out[:, -1])\n        _, next_word = torch.max(prob, dim=1)\n        next_word = next_word.item()\n\n        ys = torch.cat([ys,\n                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n        if next_word == EOS_IDX:\n            break\n    return ys\n\n\n# actual function to translate input sentence into target language\ndef translate(model: torch.nn.Module, src_sentence: str):\n    model.eval()\n    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n    num_tokens = src.shape[0]\n    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n    tgt_tokens = greedy_decode(\n        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")","metadata":{"execution":{"iopub.status.busy":"2024-03-26T14:55:14.048982Z","iopub.execute_input":"2024-03-26T14:55:14.049311Z","iopub.status.idle":"2024-03-26T15:00:59.670807Z","shell.execute_reply.started":"2024-03-26T14:55:14.049285Z","shell.execute_reply":"2024-03-26T15:00:59.669724Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"Epoch:1:   0%|          | 0/1250 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\n                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch:1, Avg Train Loss: 5.551319427871704\nEpoch: 1, Train loss: 5.551, Val loss: 6.650, Epoch time = 170.824s\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch:2, Avg Train Loss: 4.6516771333694455\nEpoch: 2, Train loss: 4.652, Val loss: 6.225, Epoch time = 169.130s\n","output_type":"stream"}]},{"cell_type":"code","source":"print(translate(transformer, \"Wiederaufnahme der Sitzungsperiode .\"))","metadata":{"execution":{"iopub.status.busy":"2024-03-26T15:02:07.831770Z","iopub.execute_input":"2024-03-26T15:02:07.832221Z","iopub.status.idle":"2024-03-26T15:02:07.880909Z","shell.execute_reply.started":"2024-03-26T15:02:07.832188Z","shell.execute_reply":"2024-03-26T15:02:07.879810Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":" The vote on the vote . \n","output_type":"stream"}]},{"cell_type":"code","source":"# from time import sleep\n# for i in tqdm(range(100),desc=\"COVAXIN\",unit=\"KAGGLE\"):\n#     sleep(0.01)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T15:00:59.802674Z","iopub.execute_input":"2024-03-26T15:00:59.803055Z","iopub.status.idle":"2024-03-26T15:00:59.807320Z","shell.execute_reply.started":"2024-03-26T15:00:59.803018Z","shell.execute_reply":"2024-03-26T15:00:59.806335Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-03-26T15:00:59.808507Z","iopub.execute_input":"2024-03-26T15:00:59.808933Z","iopub.status.idle":"2024-03-26T15:00:59.979524Z","shell.execute_reply.started":"2024-03-26T15:00:59.808905Z","shell.execute_reply":"2024-03-26T15:00:59.978371Z"},"trusted":true},"execution_count":23,"outputs":[]}]}